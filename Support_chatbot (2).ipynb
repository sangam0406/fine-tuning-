{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fed7ae8e7e5648ec81acfe9a421ca865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_185b5cd3d47c48c296a82a6d3e21d706",
              "IPY_MODEL_42fe71cda2524e2987b21894bb24b29d",
              "IPY_MODEL_08ef3b94581c4b6a9adac18d8720e521"
            ],
            "layout": "IPY_MODEL_d7ecbc3f757b4543a673a2a02f59d680"
          }
        },
        "185b5cd3d47c48c296a82a6d3e21d706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b9fdfd9997e44dcb3023ad1ce3b777b",
            "placeholder": "​",
            "style": "IPY_MODEL_a681840cb5fb40c7844504f2b3d325e4",
            "value": "config.json: 100%"
          }
        },
        "42fe71cda2524e2987b21894bb24b29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20e10121897b4d088096329ab6f3b411",
            "max": 1473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_292f483c03d6462ba7f7ab098ea0e8c3",
            "value": 1473
          }
        },
        "08ef3b94581c4b6a9adac18d8720e521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8648ad6c9d54472d8960e26f9da49d5c",
            "placeholder": "​",
            "style": "IPY_MODEL_e4a7ea7a444d48bf986f71350e870479",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 39.3kB/s]"
          }
        },
        "d7ecbc3f757b4543a673a2a02f59d680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9fdfd9997e44dcb3023ad1ce3b777b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a681840cb5fb40c7844504f2b3d325e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20e10121897b4d088096329ab6f3b411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292f483c03d6462ba7f7ab098ea0e8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8648ad6c9d54472d8960e26f9da49d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4a7ea7a444d48bf986f71350e870479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e40e480c09124aa2a6a052aa21e61b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6ce6f0591d248e28877d48223adc373",
              "IPY_MODEL_0d9fdb73d88f42b5842b8bb6bf43580e",
              "IPY_MODEL_44c60135c74e42059f210785343f8dc3"
            ],
            "layout": "IPY_MODEL_7f6f3016273b4e799ed3751ac6067397"
          }
        },
        "c6ce6f0591d248e28877d48223adc373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09c4be25eebf4f57a8fa42d40c904405",
            "placeholder": "​",
            "style": "IPY_MODEL_088caf8cb4bb47288a5973b604cd512c",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0d9fdb73d88f42b5842b8bb6bf43580e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95fb6cc4c7554c069c64dc38b98b3e50",
            "max": 312087523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d87564398394e8e96323dddafe00a77",
            "value": 312087523
          }
        },
        "44c60135c74e42059f210785343f8dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64a8a32fc0bc42f4b4bf5fcceb8406a9",
            "placeholder": "​",
            "style": "IPY_MODEL_648d871aa8b649d59e7900e313780393",
            "value": " 312M/312M [00:04&lt;00:00, 91.4MB/s]"
          }
        },
        "7f6f3016273b4e799ed3751ac6067397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c4be25eebf4f57a8fa42d40c904405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088caf8cb4bb47288a5973b604cd512c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95fb6cc4c7554c069c64dc38b98b3e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d87564398394e8e96323dddafe00a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64a8a32fc0bc42f4b4bf5fcceb8406a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "648d871aa8b649d59e7900e313780393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c17f6b80259e4af4a8c241075428e8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcf20b8cc39f41ae87a7764a2fcf09c6",
              "IPY_MODEL_c7b8fe61780d430190febc2001623c78",
              "IPY_MODEL_7657ca8154294247ac80d1f7287461b1"
            ],
            "layout": "IPY_MODEL_e1c8faba0b7942d59d234b8d9c81c709"
          }
        },
        "dcf20b8cc39f41ae87a7764a2fcf09c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca151bea3e0a44648259f874e5b15260",
            "placeholder": "​",
            "style": "IPY_MODEL_4c974510a3bf4e91a8f427bdca7583b8",
            "value": "generation_config.json: 100%"
          }
        },
        "c7b8fe61780d430190febc2001623c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56320f75e1884e518ea1ea10c00c3e03",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4a2fb271f5142289ba3fa81ec1e3594",
            "value": 293
          }
        },
        "7657ca8154294247ac80d1f7287461b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52f807c61f234860abe369adc7bad027",
            "placeholder": "​",
            "style": "IPY_MODEL_3f6e94defd1d4c2ab7f1931c0f288ae4",
            "value": " 293/293 [00:00&lt;00:00, 4.23kB/s]"
          }
        },
        "e1c8faba0b7942d59d234b8d9c81c709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca151bea3e0a44648259f874e5b15260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c974510a3bf4e91a8f427bdca7583b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56320f75e1884e518ea1ea10c00c3e03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a2fb271f5142289ba3fa81ec1e3594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52f807c61f234860abe369adc7bad027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f6e94defd1d4c2ab7f1931c0f288ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d7f552f20d0481eba8e25b1bcbbb256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfc9ca63dbbb44aab2858a7fa1673623",
              "IPY_MODEL_911df1aed42c48f0a52a3b6163ad169c",
              "IPY_MODEL_6940d3b033564983bdfa6a3e0f4ea5a7"
            ],
            "layout": "IPY_MODEL_aefae107b3504b5a99a7715a685c5507"
          }
        },
        "bfc9ca63dbbb44aab2858a7fa1673623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a39bff61df244f20834ce926f59d7a7c",
            "placeholder": "​",
            "style": "IPY_MODEL_37eaad29183a4f7a896482f5bff94322",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "911df1aed42c48f0a52a3b6163ad169c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dfd50e84f064de8b050a3d765b43151",
            "max": 44,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba0bd5b6de32479983b70a781497220c",
            "value": 44
          }
        },
        "6940d3b033564983bdfa6a3e0f4ea5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4238146d3af54b6bb213602069c1c645",
            "placeholder": "​",
            "style": "IPY_MODEL_b49bbb4de33d43118a714d50904e76bb",
            "value": " 44.0/44.0 [00:00&lt;00:00, 1.03kB/s]"
          }
        },
        "aefae107b3504b5a99a7715a685c5507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a39bff61df244f20834ce926f59d7a7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37eaad29183a4f7a896482f5bff94322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dfd50e84f064de8b050a3d765b43151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba0bd5b6de32479983b70a781497220c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4238146d3af54b6bb213602069c1c645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b49bbb4de33d43118a714d50904e76bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c7105ac96f843e980e1549d8121f4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bba7815761c44d2afe3a6ed0a309c66",
              "IPY_MODEL_30faeda985e9436aa10027b821bd3d01",
              "IPY_MODEL_c584fe3f6af3499ebe9016e203eec1f4"
            ],
            "layout": "IPY_MODEL_9df6854621fc423ba62d9b7eee68516b"
          }
        },
        "9bba7815761c44d2afe3a6ed0a309c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752de6d5ccb14566a43fb6758aa3ab9b",
            "placeholder": "​",
            "style": "IPY_MODEL_d06ac9559f864a6d806cecc62c140549",
            "value": "source.spm: 100%"
          }
        },
        "30faeda985e9436aa10027b821bd3d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1040f150de547a7836b006fbf43546f",
            "max": 801636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd774469248240abb0e8b97b472804c3",
            "value": 801636
          }
        },
        "c584fe3f6af3499ebe9016e203eec1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a386a585f7ce45329948a82a18e7eca9",
            "placeholder": "​",
            "style": "IPY_MODEL_c60bde2cac064d749108bb0332cfd6ae",
            "value": " 802k/802k [00:00&lt;00:00, 3.60MB/s]"
          }
        },
        "9df6854621fc423ba62d9b7eee68516b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752de6d5ccb14566a43fb6758aa3ab9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d06ac9559f864a6d806cecc62c140549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1040f150de547a7836b006fbf43546f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd774469248240abb0e8b97b472804c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a386a585f7ce45329948a82a18e7eca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c60bde2cac064d749108bb0332cfd6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fa0bb2b8c6246deaaf4bb56beef33b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fba990f873084c7c82727ba389640058",
              "IPY_MODEL_6cc9a68659e9402aa3900e436358ca65",
              "IPY_MODEL_dae3d1d7d1d14bd7a5f22bdc9b5aa01d"
            ],
            "layout": "IPY_MODEL_04f115973dc44e2dbba731a316ec7365"
          }
        },
        "fba990f873084c7c82727ba389640058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e368c7c1a24c454fb322dd05fc1f096b",
            "placeholder": "​",
            "style": "IPY_MODEL_dbbcaff7fd354c14b07f6d8ebcd4b923",
            "value": "target.spm: 100%"
          }
        },
        "6cc9a68659e9402aa3900e436358ca65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc2d1c0f2d9945008c8f5eb1507e8712",
            "max": 825924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e60e036bec254630ba16c87f1c5da35c",
            "value": 825924
          }
        },
        "dae3d1d7d1d14bd7a5f22bdc9b5aa01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00d5dba3a0a640bfa10b1155b29d54f8",
            "placeholder": "​",
            "style": "IPY_MODEL_48f2e82fa8774da09f0c09632ad83f98",
            "value": " 826k/826k [00:00&lt;00:00, 1.43MB/s]"
          }
        },
        "04f115973dc44e2dbba731a316ec7365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e368c7c1a24c454fb322dd05fc1f096b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbcaff7fd354c14b07f6d8ebcd4b923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc2d1c0f2d9945008c8f5eb1507e8712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e60e036bec254630ba16c87f1c5da35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00d5dba3a0a640bfa10b1155b29d54f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48f2e82fa8774da09f0c09632ad83f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4097130e6f747fc8e420668e07a15eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3d350965d61428287f06bc54d0c5061",
              "IPY_MODEL_c0397a675729495b9369773f300e7abd",
              "IPY_MODEL_86fdae826eeb461c9b529853cf47331f"
            ],
            "layout": "IPY_MODEL_f7e46ae7ed5f4c389622caa430fbb1bd"
          }
        },
        "f3d350965d61428287f06bc54d0c5061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad372e01b4df487fac0dd6c677c1fa9b",
            "placeholder": "​",
            "style": "IPY_MODEL_83262a5215b24168b36654474250fc2d",
            "value": "vocab.json: 100%"
          }
        },
        "c0397a675729495b9369773f300e7abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf34143a108e4a30b8da465a4df0743d",
            "max": 1590040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93ce53003f3c438884bc80c1d39e2bf5",
            "value": 1590040
          }
        },
        "86fdae826eeb461c9b529853cf47331f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5985453560408c9bb01e164403f259",
            "placeholder": "​",
            "style": "IPY_MODEL_e2413c2fa0334f98a5a514fe1009d61a",
            "value": " 1.59M/1.59M [00:00&lt;00:00, 2.73MB/s]"
          }
        },
        "f7e46ae7ed5f4c389622caa430fbb1bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad372e01b4df487fac0dd6c677c1fa9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83262a5215b24168b36654474250fc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf34143a108e4a30b8da465a4df0743d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ce53003f3c438884bc80c1d39e2bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a5985453560408c9bb01e164403f259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2413c2fa0334f98a5a514fe1009d61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9130cfffd26b4578a63c7837287d85c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecaa66522ba14cd492adc15f56446187",
              "IPY_MODEL_72ea4d65324643459f706c5c55eb9596",
              "IPY_MODEL_b22b9e6e37564a24b0ca71ecfc25df51"
            ],
            "layout": "IPY_MODEL_be51bafb71534752b787b7f78ffe01a3"
          }
        },
        "ecaa66522ba14cd492adc15f56446187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dc43207c7a541aaa2e82c133ac94458",
            "placeholder": "​",
            "style": "IPY_MODEL_d6bb57ed9dc841e48c532a96c4ecca85",
            "value": "config.json: 100%"
          }
        },
        "72ea4d65324643459f706c5c55eb9596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52a64e713f2a4ae2bbeebe3e7492ce58",
            "max": 1394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99a3a00817fe4b2ebaf06a61cbe69947",
            "value": 1394
          }
        },
        "b22b9e6e37564a24b0ca71ecfc25df51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce2e233894a148fb8669f7ec61c33f61",
            "placeholder": "​",
            "style": "IPY_MODEL_b6522f91060048c98294dc5e8fc85d5d",
            "value": " 1.39k/1.39k [00:00&lt;00:00, 78.0kB/s]"
          }
        },
        "be51bafb71534752b787b7f78ffe01a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dc43207c7a541aaa2e82c133ac94458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6bb57ed9dc841e48c532a96c4ecca85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52a64e713f2a4ae2bbeebe3e7492ce58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99a3a00817fe4b2ebaf06a61cbe69947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce2e233894a148fb8669f7ec61c33f61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6522f91060048c98294dc5e8fc85d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e0637399b0c42ce89c8caa041204c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_659e4544c1e148fd9a5990b78a95166a",
              "IPY_MODEL_a88204d28a644425a054e06a9d3efc38",
              "IPY_MODEL_7647447768bf49d7b2c051619a9a9478"
            ],
            "layout": "IPY_MODEL_043085c9d93e4bb786292dbec960a1d9"
          }
        },
        "659e4544c1e148fd9a5990b78a95166a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98b3b04f7e324f0882ab88d9fcc30b52",
            "placeholder": "​",
            "style": "IPY_MODEL_c09b4af8cd7048deaa43214a917fe73d",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "a88204d28a644425a054e06a9d3efc38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a0f60fdacf2481a922c35d08147d2e2",
            "max": 305826357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3715327e488949e9a1c3fb8110d5052b",
            "value": 305826357
          }
        },
        "7647447768bf49d7b2c051619a9a9478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f9536b5e3349d99eedecf60cfae3ea",
            "placeholder": "​",
            "style": "IPY_MODEL_4db58389d81244f0a0b39398cc1579f6",
            "value": " 306M/306M [00:14&lt;00:00, 22.3MB/s]"
          }
        },
        "043085c9d93e4bb786292dbec960a1d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b3b04f7e324f0882ab88d9fcc30b52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c09b4af8cd7048deaa43214a917fe73d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a0f60fdacf2481a922c35d08147d2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3715327e488949e9a1c3fb8110d5052b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9f9536b5e3349d99eedecf60cfae3ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db58389d81244f0a0b39398cc1579f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c86788ca4d744f98a33e1e0559a3d329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18f0045912b948dba6f1593d6534e686",
              "IPY_MODEL_f8df02a629ad466e9072edd38a72decc",
              "IPY_MODEL_842939e804644c66be1fed94bf669287"
            ],
            "layout": "IPY_MODEL_651d4af14e3a48f09ffc9b42c1d6a27c"
          }
        },
        "18f0045912b948dba6f1593d6534e686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd810388ff814345937c73ec08ef94b3",
            "placeholder": "​",
            "style": "IPY_MODEL_c9f8985c290b4d1a9cf67d918a8c7160",
            "value": "generation_config.json: 100%"
          }
        },
        "f8df02a629ad466e9072edd38a72decc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b58fc8fca29c47eb8a9b96ce17f809cb",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f15362919383423d983b98b2445c17b9",
            "value": 293
          }
        },
        "842939e804644c66be1fed94bf669287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7757a076fea4ce9a05dad92d43ff5bc",
            "placeholder": "​",
            "style": "IPY_MODEL_130d88d1c2ac4b5b92aae4620a535ca9",
            "value": " 293/293 [00:00&lt;00:00, 14.1kB/s]"
          }
        },
        "651d4af14e3a48f09ffc9b42c1d6a27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd810388ff814345937c73ec08ef94b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9f8985c290b4d1a9cf67d918a8c7160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b58fc8fca29c47eb8a9b96ce17f809cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f15362919383423d983b98b2445c17b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7757a076fea4ce9a05dad92d43ff5bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130d88d1c2ac4b5b92aae4620a535ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70f5183218444b37b2ede00aa2d60f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3a4ea3023fb4780be0b3a96299ef2d5",
              "IPY_MODEL_ea8ff39ae7b344edb89f9c7b85a917b4",
              "IPY_MODEL_03b77f429c904db7917dbc437788433d"
            ],
            "layout": "IPY_MODEL_565eea2c2ca7411d9c7c945a379dca83"
          }
        },
        "c3a4ea3023fb4780be0b3a96299ef2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c7ea5c20149422c93f113796a15903d",
            "placeholder": "​",
            "style": "IPY_MODEL_e577175a851746efb10c7574cc8e107d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ea8ff39ae7b344edb89f9c7b85a917b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c39985c444943e0b4a9c92efba184a1",
            "max": 44,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd2088e1945e4b648e357e4835b07480",
            "value": 44
          }
        },
        "03b77f429c904db7917dbc437788433d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_781bf6e433c649c3b4582dcf2f9f458f",
            "placeholder": "​",
            "style": "IPY_MODEL_a587c616f354413392a31ef5d217ef55",
            "value": " 44.0/44.0 [00:00&lt;00:00, 2.55kB/s]"
          }
        },
        "565eea2c2ca7411d9c7c945a379dca83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c7ea5c20149422c93f113796a15903d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e577175a851746efb10c7574cc8e107d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c39985c444943e0b4a9c92efba184a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2088e1945e4b648e357e4835b07480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "781bf6e433c649c3b4582dcf2f9f458f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a587c616f354413392a31ef5d217ef55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a5972eb31164689a01ab9b4cab32a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39bfdec49ae14084acaddef206257f32",
              "IPY_MODEL_1782a1a9b9d74c1097112720a286a00d",
              "IPY_MODEL_f49f779a2d314261b54273359b63f25e"
            ],
            "layout": "IPY_MODEL_e7891eb234b7416eaac2cfe6a164d0ed"
          }
        },
        "39bfdec49ae14084acaddef206257f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32097bb682a74612b8c24544f4729b72",
            "placeholder": "​",
            "style": "IPY_MODEL_6bca69362b6f4dbf8ac8645e74bac564",
            "value": "source.spm: 100%"
          }
        },
        "1782a1a9b9d74c1097112720a286a00d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_733985f895fd4841ab6d6881a841e1f2",
            "max": 812240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc4f271d78ff4d40bc460db55453ccb6",
            "value": 812240
          }
        },
        "f49f779a2d314261b54273359b63f25e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29039792787f48af91e643d0131affe3",
            "placeholder": "​",
            "style": "IPY_MODEL_9514b291acc54ccdb6f226d509102d4f",
            "value": " 812k/812k [00:00&lt;00:00, 18.0MB/s]"
          }
        },
        "e7891eb234b7416eaac2cfe6a164d0ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32097bb682a74612b8c24544f4729b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bca69362b6f4dbf8ac8645e74bac564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "733985f895fd4841ab6d6881a841e1f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc4f271d78ff4d40bc460db55453ccb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29039792787f48af91e643d0131affe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9514b291acc54ccdb6f226d509102d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62b85b1aadee4555a818e489e74fa3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dccacfb7d30a4a27a13b0590719fee17",
              "IPY_MODEL_04c7f3e142a04ed5aef97537c6a7039e",
              "IPY_MODEL_ffb92f8daff84bba8a09914ea75dda27"
            ],
            "layout": "IPY_MODEL_dd22b645880d4aac9028c275d9acccae"
          }
        },
        "dccacfb7d30a4a27a13b0590719fee17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_422de2ff75c045b88503dac21ef60bb9",
            "placeholder": "​",
            "style": "IPY_MODEL_9532c99572a8426dbb3813b0c9a10edc",
            "value": "target.spm: 100%"
          }
        },
        "04c7f3e142a04ed5aef97537c6a7039e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e17ae35ec1a46a8a85d468df162a877",
            "max": 1067935,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3bd7361c15749cebb66cf962f498124",
            "value": 1067935
          }
        },
        "ffb92f8daff84bba8a09914ea75dda27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa3b65f5668c4158851191edf80891e0",
            "placeholder": "​",
            "style": "IPY_MODEL_0638baa5e3064615bf793f37854d5da5",
            "value": " 1.07M/1.07M [00:00&lt;00:00, 37.8MB/s]"
          }
        },
        "dd22b645880d4aac9028c275d9acccae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "422de2ff75c045b88503dac21ef60bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9532c99572a8426dbb3813b0c9a10edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e17ae35ec1a46a8a85d468df162a877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3bd7361c15749cebb66cf962f498124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa3b65f5668c4158851191edf80891e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0638baa5e3064615bf793f37854d5da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dae7735a9f2942b7a227cd69ff88a0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ec636d601a4457a80711c91a004e849",
              "IPY_MODEL_0dc47d36d2544b4c8908b82e27b5b0d4",
              "IPY_MODEL_bb7045de46e847bf847383ef6411520d"
            ],
            "layout": "IPY_MODEL_66a4c4c60d43465a82501b843d0e92df"
          }
        },
        "8ec636d601a4457a80711c91a004e849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1bf21b786fe45f2b509faf3a7315702",
            "placeholder": "​",
            "style": "IPY_MODEL_81be804ab91c40b4bde859166f723532",
            "value": "vocab.json: 100%"
          }
        },
        "0dc47d36d2544b4c8908b82e27b5b0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1d5f06152f43b798ede48ebcdc4386",
            "max": 2097836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2190203e4ced46469b5c86e383df37fa",
            "value": 2097836
          }
        },
        "bb7045de46e847bf847383ef6411520d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a7724f11927489d8f159439265df18b",
            "placeholder": "​",
            "style": "IPY_MODEL_261e32c13eda47d3b328f63c6b313dad",
            "value": " 2.10M/2.10M [00:00&lt;00:00, 8.99MB/s]"
          }
        },
        "66a4c4c60d43465a82501b843d0e92df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1bf21b786fe45f2b509faf3a7315702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81be804ab91c40b4bde859166f723532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1d5f06152f43b798ede48ebcdc4386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2190203e4ced46469b5c86e383df37fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a7724f11927489d8f159439265df18b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "261e32c13eda47d3b328f63c6b313dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b3b42d59f7d4b8aa2471cfac519e21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3cab7d059fa4267a734fc2083b971ac",
              "IPY_MODEL_78c5eb51376c46ea8178e7df8cf58071",
              "IPY_MODEL_cc8d6e614c024b39aedf8759f7afe2ad"
            ],
            "layout": "IPY_MODEL_2ee707a5073d4f1e912d55cb062b0e50"
          }
        },
        "d3cab7d059fa4267a734fc2083b971ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c2fdad6928b4d86aa62b05125bd4240",
            "placeholder": "​",
            "style": "IPY_MODEL_c0737f7b928949e08e8f423581609ac6",
            "value": "config.json: 100%"
          }
        },
        "78c5eb51376c46ea8178e7df8cf58071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_476aa9e8c565458f95762be1ca37a91b",
            "max": 507,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f99236a494494925b1d2db678bd1d887",
            "value": 507
          }
        },
        "cc8d6e614c024b39aedf8759f7afe2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a72020cbee4e44a394887110d9fcbf3f",
            "placeholder": "​",
            "style": "IPY_MODEL_bc47420103eb4f74949f0649a302a766",
            "value": " 507/507 [00:00&lt;00:00, 29.9kB/s]"
          }
        },
        "2ee707a5073d4f1e912d55cb062b0e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2fdad6928b4d86aa62b05125bd4240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0737f7b928949e08e8f423581609ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "476aa9e8c565458f95762be1ca37a91b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f99236a494494925b1d2db678bd1d887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a72020cbee4e44a394887110d9fcbf3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc47420103eb4f74949f0649a302a766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c9fae0be16b4e158e985f44dfbe3392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3af4ac24a945497d81f4123be9682902",
              "IPY_MODEL_6f0c3219efa3448ba9df9cdc4f964edb",
              "IPY_MODEL_d2a949a810634c4aafebf649bad2c98a"
            ],
            "layout": "IPY_MODEL_c2534b1d31934f6a993e0c34cb982e7a"
          }
        },
        "3af4ac24a945497d81f4123be9682902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4e0484a25f749e281b5e3d0ade32379",
            "placeholder": "​",
            "style": "IPY_MODEL_95955fdee2434bd3a616bfcf46ea8b0e",
            "value": "spiece.model: 100%"
          }
        },
        "6f0c3219efa3448ba9df9cdc4f964edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02a0fa17bbd74da8a9953d0f0eea0ea6",
            "max": 5646064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cb745bce5db45898618e3f6d0622204",
            "value": 5646064
          }
        },
        "d2a949a810634c4aafebf649bad2c98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c828d8b92637480f8ff2a1c07151e59e",
            "placeholder": "​",
            "style": "IPY_MODEL_4d27e75a0e40458fa1ca9d8441f53a0b",
            "value": " 5.65M/5.65M [00:01&lt;00:00, 4.13MB/s]"
          }
        },
        "c2534b1d31934f6a993e0c34cb982e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e0484a25f749e281b5e3d0ade32379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95955fdee2434bd3a616bfcf46ea8b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02a0fa17bbd74da8a9953d0f0eea0ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb745bce5db45898618e3f6d0622204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c828d8b92637480f8ff2a1c07151e59e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d27e75a0e40458fa1ca9d8441f53a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9G1Oz9DIWHt0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "6a8acfb5-1e44-4d0e-b614-bd8d06b2a855"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'BaseTransport' from 'httpx' (/usr/local/lib/python3.10/dist-packages/httpx/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4e970ef9e648>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbase64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotGiven\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProxiesTypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_from_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/types/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/types/batch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch_error\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch_request_counts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchRequestCounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFieldInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m from ._types import (\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mBody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mIncEx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhttpx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseTransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAsyncBaseTransport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'BaseTransport' from 'httpx' (/usr/local/lib/python3.10/dist-packages/httpx/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "from IPython.display import HTML, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "import spacy\n",
        "from googletrans import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# HTML/JavaScript for recording audio in Colab\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement('div');\n",
        "var my_p = document.createElement('p');\n",
        "my_p.innerHTML = \"Click the button to start recording:\";\n",
        "my_div.appendChild(my_p);\n",
        "\n",
        "var my_button = document.createElement('button');\n",
        "my_button.innerHTML = \"Record\";\n",
        "my_button.onclick = async function() {\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "  const mediaRecorder = new MediaRecorder(stream);\n",
        "  mediaRecorder.start();\n",
        "\n",
        "  const audioChunks = [];\n",
        "  mediaRecorder.addEventListener(\"dataavailable\", event => {\n",
        "    audioChunks.push(event.data);\n",
        "  });\n",
        "\n",
        "  mediaRecorder.addEventListener(\"stop\", async () => {\n",
        "    const audioBlob = new Blob(audioChunks);\n",
        "    const reader = new FileReader();\n",
        "    reader.readAsDataURL(audioBlob);\n",
        "    reader.onloadend = () => {\n",
        "      const base64data = reader.result;\n",
        "      google.colab.kernel.invokeFunction('notebook.record_audio', [base64data], {});\n",
        "    };\n",
        "  });\n",
        "\n",
        "  setTimeout(() => {\n",
        "    mediaRecorder.stop();\n",
        "  }, 5000);\n",
        "};\n",
        "my_div.appendChild(my_button);\n",
        "document.body.appendChild(my_div);\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# Initialize SpaCy models\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize Google Translator\n",
        "translator = Translator()\n",
        "\n",
        "def translate_text_openai(text, target_language=\"en\"):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Translate the following text to {target_language}: {text}\"}\n",
        "        ]\n",
        "    )\n",
        "    translated_text = response.choices[0].message.content.strip()\n",
        "    return translated_text\n",
        "\n",
        "def translate_audio_to_text(audio_data):\n",
        "    response = openai.Audio.transcribe(\n",
        "        model=\"whisper-1\",\n",
        "        file=io.BytesIO(audio_data),\n",
        "        format=\"wav\"\n",
        "    )\n",
        "    return response[\"text\"]\n",
        "\n",
        "def extract_locations(user_input, input_language=\"en\"):\n",
        "    if input_language != \"en\":\n",
        "        user_input = translator.translate(user_input, dest=\"en\").text\n",
        "\n",
        "    # Define keywords that indicate a direction or route request\n",
        "    direction_keywords = [\"from\", \"to\", \"take\", \"route\", \"drive\"]\n",
        "\n",
        "    # Split user input into words\n",
        "    words = user_input.lower().split()\n",
        "\n",
        "    # Initialize variables to store start and end locations\n",
        "    start_location = None\n",
        "    end_location = None\n",
        "\n",
        "    # Use English SpaCy model for extraction\n",
        "    doc = nlp_en(user_input)\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"LOC\":\n",
        "            if start_location is None:\n",
        "                start_location = ent.text.capitalize()  # Assuming location is in title case\n",
        "            elif end_location is None:\n",
        "                end_location = ent.text.capitalize()  # Assuming location is in title case\n",
        "\n",
        "    # Fallback to keyword-based extraction for other languages or if no entities found\n",
        "    if not start_location or not end_location:\n",
        "        for i in range(len(words)):\n",
        "            if words[i] in direction_keywords:\n",
        "                if i + 1 < len(words):\n",
        "                    if start_location is None:\n",
        "                        start_location = words[i + 1].capitalize()  # Assuming location is in title case\n",
        "                    elif end_location is None:\n",
        "                        end_location = words[i + 1].capitalize()  # Assuming location is in title case\n",
        "\n",
        "    return start_location, end_location\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def main():\n",
        "    print(\"Route Description Chatbot. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        input_type = input(\"Enter 'text' for text input or 'audio' for audio input: \").strip().lower()\n",
        "\n",
        "        if input_type == 'exit':\n",
        "            print('Exiting')\n",
        "            break\n",
        "\n",
        "        if input_type not in ['text', 'audio']:\n",
        "            print(\"Invalid input type. Please enter 'text' or 'audio'.\")\n",
        "            continue\n",
        "\n",
        "        if input_type == 'audio':\n",
        "            display(HTML(AUDIO_HTML))\n",
        "            data = eval_js(\"base64data\")\n",
        "            binary = b64decode(data.split(',')[1])\n",
        "\n",
        "            process = (\n",
        "                ffmpeg.input('pipe:0')\n",
        "                .output('pipe:1', format='wav')\n",
        "                .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True, input=binary)\n",
        "            )\n",
        "            output, _ = process.communicate()\n",
        "\n",
        "            riff_chunk_size = len(output) - 8\n",
        "            q = riff_chunk_size\n",
        "            b = []\n",
        "            for i in range(4):\n",
        "                q, r = divmod(q, 256)\n",
        "                b.append(r)\n",
        "\n",
        "            riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "            sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "            audio_data = translate_audio_to_text(audio.tobytes())\n",
        "            print(\"Translated Audio:\", audio_data)\n",
        "\n",
        "            # Detect language of audio input\n",
        "            input_language = \"hi\" if any('\\u0900' <= char <= '\\u097f' for char in audio_data) else \"en\"\n",
        "\n",
        "            start_location, end_location = extract_locations(audio_data, input_language)\n",
        "            if not start_location or not end_location:\n",
        "                print(\"Could not extract start and end locations from input. Please try again.\")\n",
        "                continue\n",
        "\n",
        "            route_description = generate_route_description(start_location, end_location)\n",
        "            print(\"Route Description:\", route_description)\n",
        "\n",
        "        else:\n",
        "            user_input = input(\"Enter your request: \")\n",
        "\n",
        "            language_code = None\n",
        "            if \":\" in user_input:\n",
        "                parts = user_input.split(\":\")\n",
        "                user_input = parts[0].strip()\n",
        "                language_code = parts[1].strip().lower()\n",
        "\n",
        "            start_location, end_location = extract_locations(user_input, language_code)\n",
        "            if not start_location or not end_location:\n",
        "                print(\"Could not extract start and end locations from input. Please try again.\")\n",
        "                continue\n",
        "\n",
        "            route_description = generate_route_description(start_location, end_location)\n",
        "            print(\"Route Description:\", route_description)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai transformers spacy pydub\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install ffmpeg-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epe8-YLSu4KL",
        "outputId": "c514fa19-9c3e-45cf-c6bc-4b03462e93a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (2.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from IPython.display import HTML, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\n",
        "\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# HTML/JavaScript for recording audio in Colab\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement('div');\n",
        "var my_p = document.createElement('p');\n",
        "my_p.innerHTML = \"Click the button to start recording:\";\n",
        "my_div.appendChild(my_p);\n",
        "\n",
        "var my_button = document.createElement('button');\n",
        "my_button.innerHTML = \"Record\";\n",
        "my_button.onclick = async function() {\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "  const mediaRecorder = new MediaRecorder(stream);\n",
        "  mediaRecorder.start();\n",
        "\n",
        "  const audioChunks = [];\n",
        "  mediaRecorder.addEventListener(\"dataavailable\", event => {\n",
        "    audioChunks.push(event.data);\n",
        "  });\n",
        "\n",
        "  mediaRecorder.addEventListener(\"stop\", async () => {\n",
        "    const audioBlob = new Blob(audioChunks);\n",
        "    const reader = new FileReader();\n",
        "    reader.readAsDataURL(audioBlob);\n",
        "    reader.onloadend = () => {\n",
        "      const base64data = reader.result;\n",
        "      google.colab.kernel.invokeFunction('notebook.record_audio', [base64data], {});\n",
        "    };\n",
        "  });\n",
        "\n",
        "  setTimeout(() => {\n",
        "    mediaRecorder.stop();\n",
        "  }, 5000);\n",
        "};\n",
        "my_div.appendChild(my_button);\n",
        "document.body.appendChild(my_div);\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# Initialize SpaCy models\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Initialize Hugging Face translation pipeline\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-hi-en\")\n",
        "\n",
        "def translate_text_openai(text, target_language=\"en\"):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Translate the following text to {target_language}: {text}\"}\n",
        "        ]\n",
        "    )\n",
        "    translated_text = response.choices[0].message.content.strip()\n",
        "    return translated_text\n",
        "\n",
        "def translate_audio_to_text(audio_data):\n",
        "    response = openai.Audio.transcribe(\n",
        "        model=\"whisper-1\",\n",
        "        file=io.BytesIO(audio_data),\n",
        "        format=\"wav\"\n",
        "    )\n",
        "    return response[\"text\"]\n",
        "\n",
        "def extract_locations(user_input, input_language=\"en\"):\n",
        "    if input_language != \"en\":\n",
        "        translated_input = translator(user_input)[0]['translation_text']\n",
        "    else:\n",
        "        translated_input = user_input\n",
        "\n",
        "    # Define keywords that indicate a direction or route request\n",
        "    direction_keywords = [\"from\", \"to\", \"take\", \"route\", \"drive\"]\n",
        "\n",
        "    # Split user input into words\n",
        "    words = translated_input.lower().split()\n",
        "\n",
        "    # Initialize variables to store start and end locations\n",
        "    start_location = None\n",
        "    end_location = None\n",
        "\n",
        "    # Use English SpaCy model for extraction\n",
        "    doc = nlp_en(translated_input)\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"LOC\":\n",
        "            if start_location is None:\n",
        "                start_location = ent.text.capitalize()  # Assuming location is in title case\n",
        "            elif end_location is None:\n",
        "                end_location = ent.text.capitalize()  # Assuming location is in title case\n",
        "\n",
        "    # Fallback to keyword-based extraction for other languages or if no entities found\n",
        "    if not start_location or not end_location:\n",
        "        for i in range(len(words)):\n",
        "            if words[i] in direction_keywords:\n",
        "                if i + 1 < len(words):\n",
        "                    if start_location is None:\n",
        "                        start_location = words[i + 1].capitalize()  # Assuming location is in title case\n",
        "                    elif end_location is None:\n",
        "                        end_location = words[i + 1].capitalize()  # Assuming location is in title case\n",
        "\n",
        "    return start_location, end_location\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def main():\n",
        "    print(\"Route Description Chatbot. Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        input_type = input(\"Enter 'text' for text input or 'audio' for audio input: \").strip().lower()\n",
        "\n",
        "        if input_type == 'exit':\n",
        "            print('Exiting')\n",
        "            break\n",
        "\n",
        "        if input_type not in ['text', 'audio']:\n",
        "            print(\"Invalid input type. Please enter 'text' or 'audio'.\")\n",
        "            continue\n",
        "\n",
        "       if input_type == 'audio':\n",
        "            display(HTML(AUDIO_HTML))\n",
        "            data = eval_js(\"base64data\")\n",
        "            binary = b64decode(data.split(',')[1])\n",
        "\n",
        "            process = (\n",
        "                ffmpeg.input('pipe:0')\n",
        "                .output('pipe:1', format='wav')\n",
        "                .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True, input=binary)\n",
        "            )\n",
        "            output, _ = process.communicate()\n",
        "\n",
        "            riff_chunk_size = len(output) - 8\n",
        "            q = riff_chunk_size\n",
        "            b = []\n",
        "            for i in range(4):\n",
        "                q, r = divmod(q, 256)\n",
        "                b.append(r)\n",
        "\n",
        "            riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "            sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "            audio_data = translate_audio_to_text(audio.tobytes())\n",
        "            print(\"Translated Audio:\", audio_data)\n",
        "\n",
        "            # Detect language of audio input\n",
        "            input_language = \"hi\" if any('\\u0900' <= char <= '\\u097f' for char in audio_data) else \"en\"\n",
        "\n",
        "            start_location, end_location = extract_locations(audio_data, input_language)\n",
        "            if not start_location or not end_location:\n",
        "                print(\"Could not extract start and end locations from input. Please try again.\")\n",
        "                continue\n",
        "\n",
        "            route_description = generate_route_description(start_location, end_location)\n",
        "            print(\"Route Description:\", route_description)\n",
        "\n",
        "        else:\n",
        "            user_input = input(\"Enter your request: \")\n",
        "\n",
        "            language_code = None\n",
        "            if \":\" in user_input:\n",
        "                parts = user_input.split(\":\")\n",
        "                user_input = parts[0].strip()\n",
        "                language_code = parts[1].strip().lower()\n",
        "\n",
        "            start_location, end_location = extract_locations(user_input, language_code)\n",
        "            if not start_location or not end_location:\n",
        "                print(\"Could not extract start and end locations from input. Please try again.\")\n",
        "                continue\n",
        "\n",
        "            route_description = generate_route_description(start_location, end_location)\n",
        "            print(\"Route Description:\", route_description)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "fIKNwX7mwhwH",
        "outputId": "6ba938b7-5245-457f-aa79-99f717dd5d0b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Route Description Chatbot. Type 'exit' to quit.\n",
            "Enter 'text' for text input or 'audio' for audio input: text\n",
            "Enter your request: text\n",
            "Could not extract start and end locations from input. Please try again.\n",
            "Enter 'text' for text input or 'audio' for audio input: text\n",
            "Enter your request: from kannur to kozhikode\n",
            "Route Description: I can't provide real-time driving directions, but I can give you a general driving route from one location to another. Please provide me with the specific addresses or locations you want the route for.\n",
            "Enter 'text' for text input or 'audio' for audio input: text\n",
            "Enter your request: from kannur to kozhikode\n",
            "Route Description: I'm unable to provide a detailed driving route from a specific starting point to a specific destination without knowing the locations. Could you please provide me with the addresses or names of the starting point (%1) and the destination (%2) so that I can assist you further?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-03cacdcfd086>\u001b[0m in \u001b[0;36m<cell line: 198>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-03cacdcfd086>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Route Description Chatbot. Type 'exit' to quit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0minput_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter 'text' for text input or 'audio' for audio input: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import openai\n",
        "import re\n",
        "\n",
        "# Set the OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expression to extract locations from input\n",
        "    pattern = re.compile(r\"FROM\\s+(.+?)\\s+TO\\s+(.+)\", re.IGNORECASE)\n",
        "    match = pattern.search(user_input)\n",
        "    if match:\n",
        "        start_location = match.group(1).strip()\n",
        "        end_location = match.group(2).strip()\n",
        "        return start_location, end_location\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Route Description Chatbot. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use 'HEY TAKE ME FROM [start location] TO [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description:\", route_description)\n"
      ],
      "metadata": {
        "id": "P6DfHKUR4gfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description:\", route_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5Bxvjbawiqs",
        "outputId": "48674f16-db2f-459f-cfdb-a2114eac9433"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: tAKE ME FROM KANNUR TO KOZHIKODE\n",
            "Route Description: Sure! The approximate driving route from Kannur to Kozhikode is about 90 kilometers and takes roughly 2 to 2.5 hours, depending on traffic conditions. Here is a detailed route:\n",
            "\n",
            "1. Start your journey in Kannur and head south on the NH 66 (also known as the NH 66 or National Highway 66).\n",
            "\n",
            "2. After driving for about 25 kilometers, you will reach Thottada. Continue straight on the NH 66.\n",
            "\n",
            "3. Around the 50-kilometer mark, you will reach Vadakara. Stay on the NH 66.\n",
            "\n",
            "4. As you continue on the NH 66, after about 75 kilometers, you will reach Beypore. \n",
            "\n",
            "5. From Beypore, continue on NH 66 towards Kozhikode. After approximately 90 kilometers, you will reach your destination, Kozhikode.\n",
            "\n",
            "Here are some major landmarks along the way:\n",
            "- Kannur\n",
            "- Thottada\n",
            "- Vadakara\n",
            "- Beypore\n",
            "- Kozhikode\n",
            "\n",
            "Please note that these are approximate distances and landmarks, so it's always a good idea to have a GPS or map handy for accurate navigation during your journey. Safe travels!\n",
            "Enter your request: XIT\n",
            "Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from translate import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description  # No translation needed if English is selected\n",
        "\n",
        "    # Translate the route description to the target language\n",
        "    translator = Translator(to_lang=target_language)\n",
        "    translated_description = translator.translate(route_description)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    # Ask user for desired language for route description\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNIxRoX4Xqbl",
        "outputId": "9928b0ee-8073-4fb4-aafd-488521e5b6a8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from kannur to kozhikode\n",
            "Route Description (in English): The driving route from Kannur to Kozhikode follows NH66 and is approximately 95 kilometers long. Here is a detailed step-by-step guide with major turns, landmarks, and distances:\n",
            "\n",
            "1. Start from Kannur and head south on NH66 (also known as the Kozhikode-Kochi Road).\n",
            "2. Pass by St. Francis Assisi Cathedral on your right.\n",
            "3. Drive for about 10 kilometers until you reach Thalassery. Look out for Mahe River and Thalassery Sea Bridge.\n",
            "4. Continue on NH66 and drive through Chala, Kuthuparamba, and Kuttiattoor.\n",
            "5. After driving approximately 40 kilometers, you will reach Vadakara. Look out for Vadakara Overbridge.\n",
            "6. Continue on NH66 through regions like Thottilpalam and Chorode.\n",
            "7. After driving for another 30 kilometers, you will reach Kozhikode. Look out for landmarks like Mavoor Road, Focus Mall, and Calicut Beach.\n",
            "\n",
            "Please note that road conditions and traffic may vary, so it’s advisable to check for any updates or detours before starting your journey. Enjoy your drive from Kannur to Kozhikode!\n",
            "Enter language code for translation (e.g., 'hi' for Hindi): hi\n",
            "Route Description (in hi): QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS कोड़िकोड\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from translate import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description  # No translation needed if English is selected\n",
        "\n",
        "    # Initialize translator\n",
        "    translator = Translator(to_lang=target_language)\n",
        "\n",
        "    # Split route description into manageable chunks (e.g., sentences)\n",
        "    sentences = route_description.split('. ')\n",
        "    translated_sentences = []\n",
        "\n",
        "    # Translate each sentence and join them back together\n",
        "    for sentence in sentences:\n",
        "        translated_sentence = translator.translate(sentence)\n",
        "        translated_sentences.append(translated_sentence)\n",
        "\n",
        "    translated_description = '. '.join(translated_sentences)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    # Ask user for desired language for route description\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFrbGCQkYDDm",
        "outputId": "03631b6a-8e29-472d-b0bc-ad4c2aa3f629"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from kannur to kozhikode\n",
            "Route Description (in English): Driving from Kannur to Kozhikode is a straightforward journey covering approximately 93 km and usually takes around 2 to 2.5 hours, depending on traffic conditions. Here is a detailed route with major turns, landmarks, and distances:\n",
            "\n",
            "1. Start from Kannur town center.\n",
            "2. Head southwest on National Highway 66 (NH 66) towards Kozhikode.\n",
            "3. After about 16 km, you will pass through Thalassery town.\n",
            "4. Continue on NH 66 for another 55 km until you reach Vadakara town.\n",
            "5. In Vadakara, you will pass by Vadakara bus stand and Vadakara railway station.\n",
            "6. Continue on NH 66 towards Kozhikode for about 22 km.\n",
            "7. As you approach Kozhikode, you will pass through Ramanattukara and Feroke areas.\n",
            "8. Follow the signs for Kozhikode city center.\n",
            "9. In Kozhikode, you will find landmarks like Kozhikode Beach, Mananchira Square, and Kozhikode Town Hall.\n",
            "10. Depending on your final destination within Kozhikode, follow the directions to reach your specific location.\n",
            "\n",
            "Overall, this route from Kannur to Kozhikode is well-marked with highway signs and is a popular and well-traveled route, ensuring a relatively easy and comfortable journey.\n",
            "Enter language code for translation (e.g., 'hi' for Hindi): hi\n",
            "Route Description (in hi): कन्नूर से कोझिकोड तक गाड़ी चलाना लगभग 93 किमी की सीधी यात्रा है और आमतौर पर ट्रैफ़िक की स्थिति के आधार पर इसमें लगभग 2 से 2.5 घंटे लगते हैं. यहाँ प्रमुख मोड़, लैंडमार्क और दूरी के साथ एक विस्तृत मार्ग दिया गया है:\n",
            "\n",
            "1. कन्नूर टाउन सेंटर से शुरू करें।\n",
            "2. कोझिकोड की ओर राष्ट्रीय राजमार्ग 66 (एनएच 66) पर दक्षिण - पश्चिम की ओर।\n",
            "3. लगभग 16 किमी के बाद, आप थालासेरी शहर से होकर गुजरेंगे।\n",
            "4. वडाकारा शहर तक पहुँचने तक NH 66 पर 55 किमी तक जारी रखें।\n",
            "5. वडाकरा में, आप वडाकरा बस स्टैंड और वडाकरा रेलवे स्टेशन से गुजरेंगे।\n",
            "6. एनएच 66 पर कोझिकोड की ओर लगभग 22 किमी तक जारी रखें।\n",
            "7. जैसे ही आप कोझिकोड के पास पहुंचेंगे, आप रामनट्टुकारा और फेरोके क्षेत्रों से गुजरेंगे।\n",
            "8. कोझिकोड शहर के केंद्र के लिए संकेतों का पालन करें।\n",
            "9. कोझिकोड में, आपको कोझिकोड बीच, मानचिरा स्क्वायर और कोझिकोड टाउन हॉल जैसे लैंडमार्क मिलेंगे।\n",
            "10. कोझिकोड में अपने आखिरी डेस्टिनेशन के आधार पर, अपनी खास लोकेशन तक पहुँचने के लिए निर्देशों का पालन करें।\n",
            "\n",
            "कुल मिलाकर, कन्नूर से कोझिकोड तक का यह मार्ग राजमार्ग संकेतों के साथ अच्छी तरह से चिह्नित है और यह एक लोकप्रिय और अच्छी तरह से यात्रा करने वाला मार्ग है, जो अपेक्षाकृत आसान और आरामदायक यात्रा सुनिश्चित करता है।\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from translate import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description  # No translation needed if English is selected\n",
        "    elif target_language == 'ml':\n",
        "        return translate_to_malayalam(route_description)\n",
        "    else:\n",
        "        # Initialize translator\n",
        "        translator = Translator(to_lang=target_language)\n",
        "\n",
        "        # Split route description into manageable chunks (e.g., sentences)\n",
        "        sentences = route_description.split('. ')\n",
        "        translated_sentences = []\n",
        "\n",
        "        # Translate each sentence and join them back together\n",
        "        for sentence in sentences:\n",
        "            translated_sentence = translator.translate(sentence)\n",
        "            translated_sentences.append(translated_sentence)\n",
        "\n",
        "        translated_description = '. '.join(translated_sentences)\n",
        "\n",
        "        return translated_description\n",
        "\n",
        "def translate_to_malayalam(route_description):\n",
        "    # Example of using Google Translate for Malayalam translation\n",
        "    translator = Translator(to_lang=\"ml\")\n",
        "    translated_description = translator.translate(route_description)\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    # Ask user for desired language for route description\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uCOOKjkYZ-V",
        "outputId": "c77e7c88-3f51-4509-ab30-d70e264afe35"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from thrissur to kochi\n",
            "Route Description (in English): Sure! Here is a detailed driving route from Thrissur to Kochi:\n",
            "\n",
            "- Start from Thrissur city center and head south on Shornur Road towards Round West.\n",
            "\n",
            "- Keep straight on Shornur Road for about 3.5 km until you reach the Kerala Police Academy on your left.\n",
            "\n",
            "- Continue on Shornur Road for another 2 km until you reach a large roundabout (Chettupuzha Junction). Take the second exit towards Poonkunnam.\n",
            "\n",
            "- Drive straight on Poonkunnam Road for about 1.5 km until you reach a T-junction. Turn left onto Sakthan Thampuran Road.\n",
            "\n",
            "- Follow Sakthan Thampuran Road for approximately 1.3 km until you reach a traffic signal near Sakthan Stand. Turn right onto Palace Road.\n",
            "\n",
            "- Continue on Palace Road for about 700 meters and then turn left onto West Fort Road.\n",
            "\n",
            "- Drive on West Fort Road for around 1.5 km until you reach a roundabout near Vadakkunnathan Temple. Take the second exit onto Kodungallur Shornur Road.\n",
            "\n",
            "- Follow Kodungallur Shornur Road for about 19 km until you reach a junction near Mala. Turn left onto NH544.\n",
            "\n",
            "- Continue on NH544 for approximately 2 km and then take the ramp on the right to merge onto NH66 towards Kochi.\n",
            "\n",
            "- Follow NH66 for about 45 km, passing through towns like Angamaly, Aluva, and Kalamassery.\n",
            "\n",
            "- After passing Kalamassery, continue on NH66 and drive for another 8 km until you reach Edappally. Keep following NH66.\n",
            "\n",
            "- From Edappally, drive about 7 km more on NH66 until you reach Palarivattom Junction.\n",
            "\n",
            "- Keep following NH66 for another 2 km until you reach Vyttila Junction.\n",
            "\n",
            "- At Vyttila Junction, take a right turn to enter the city of Kochi. You can then follow the signs to your specific destination within Kochi.\n",
            "\n",
            "The total distance from Thrissur to Kochi via this route is approximately 85 km, and the journey takes around 2 to 2.5 hours depending on traffic conditions. Remember to check for live traffic updates and road conditions before you start your journey.\n",
            "Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): ml\n",
            "Route Description (in ml): QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS\n",
            "Enter your request: hi\n",
            "Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from translate import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description  # No translation needed if English is selected\n",
        "    elif target_language == 'ml':\n",
        "        return translate_to_malayalam(route_description)\n",
        "    else:\n",
        "        # Initialize translator\n",
        "        translator = Translator(to_lang=target_language)\n",
        "\n",
        "        # Split route description into manageable chunks (e.g., sentences)\n",
        "        sentences = route_description.split('. ')\n",
        "        translated_sentences = []\n",
        "\n",
        "        # Translate each sentence and join them back together\n",
        "        for sentence in sentences:\n",
        "            translated_sentence = translator.translate(sentence)\n",
        "            translated_sentences.append(translated_sentence)\n",
        "\n",
        "        translated_description = '. '.join(translated_sentences)\n",
        "\n",
        "        return translated_description\n",
        "\n",
        "def translate_to_malayalam(route_description):\n",
        "    # Initialize translator for Malayalam\n",
        "    translator = Translator(to_lang=\"ml\")\n",
        "\n",
        "    # Split route description into smaller chunks due to query length limitation\n",
        "    chunk_size = 300  # Adjust chunk size based on the API's limits\n",
        "    chunks = [route_description[i:i+chunk_size] for i in range(0, len(route_description), chunk_size)]\n",
        "\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        translated_chunk = translator.translate(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "\n",
        "    translated_description = '. '.join(translated_chunks)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    # Ask user for desired language for route description\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHvvwVDqYvAZ",
        "outputId": "7e99ecbc-6160-4cad-cf3c-5d9e23f3baa1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from thrissur to kochi\n",
            "Route Description (in English): Here is a detailed driving route from Thrissur to Kochi:\n",
            "\n",
            "1. Start from Thrissur and head south on SH22 towards Puthenpally Road. (0 km)\n",
            "\n",
            "2. Continue on SH22 and merge onto NH544 towards Ernakulam/Kochi. (approx. 46 km)\n",
            "\n",
            "3. Stay on NH544 and pass through Chalakudy, Angamaly, and Aluva. Continue toward Edappally. (approx. 80 km)\n",
            "\n",
            "4. Take the Edapally - Panvel Highway/SH15 towards Kochi City. (approx. 15 km)\n",
            "\n",
            "5. Continue on SH15 and take a left onto National Highway 66 (NH66) towards Vyttila Junction. (approx. 6 km)\n",
            "\n",
            "6. At Vyttila Junction, take the left exit towards Kundannoor Bridge on the Sahodaran Ayyappan Road. (approx. 2 km)\n",
            "\n",
            "7. Cross the Kundannoor Bridge and continue straight towards Kochi city. (approx. 2 km)\n",
            "\n",
            "8. You will reach MG Road in Kochi city. Follow the signs to reach your specific destination within Kochi.\n",
            "\n",
            "Total Distance: Approximately 155 km\n",
            "\n",
            "Please note that traffic conditions and road diversions may impact the driving time, so it's advisable to check for any real-time updates or traffic alerts before starting your journey.\n",
            "Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): ml\n",
            "Route Description (in ml): തൃശ്ശൂരിൽ നിന്ന് കൊച്ചിയിലേക്കുള്ള വിശദമായ ഡ്രൈവിംഗ് റൂട്ട് ഇതാ:\n",
            "\n",
            "1. തൃശൂരിൽ നിന്ന് ആരംഭിച്ച് SH22 ന് തെക്കോട്ട് പുത്തൻപള്ളി റോഡിലേക്ക് പോകുക. (0 കിലോമീറ്റർ)\n",
            "\n",
            "2. SH22 ൽ തുടരുക, NH544 ലേക്ക് എറണാകുളം/കൊച്ചിയിലേക്ക് ലയിക്കുക. (ഏകദേശം 46 കിലോമീറ്റർ)\n",
            "\n",
            "3. NH544-ൽ തുടരുക, ചാലക്കുടി, അങ്കമാലി, ആലുവ എന്നിവിടങ്ങളിലൂടെ കടന്നുപോകുക. ടുവ തുടരുക. rd ഇടപ്പള്ളി. (ഏകദേശം 80 കി .മീ)\n",
            "\n",
            "4. ഇടപ്പള്ളി - പൻവേൽ ഹൈവേ/SH15 കൊച്ചി നഗരത്തിലേക്ക് എടുക്കുക. (ഏകദേശം 15 കിലോമീറ്റർ)\n",
            "\n",
            "5. SH15-ൽ തുടരുക, ദേശീയപാത 66 (NH66) -ൽ നിന്ന് വൈറ്റില ജംഗ്ഷനിലേക്ക് ഇടത്തോട്ട് പോകുക. (ഏകദേശം 6 കിലോമീറ്റർ)\n",
            "\n",
            "6. വൈറ്റില ജംഗ്ഷനിൽ, സാഹയിലെ കുണ്ടന്നൂർ പാലത്തിലേക്ക് ഇടത് എക്സിറ്റ് എടുക്കുക. ഒഡാരൻ അയ്യപ്പൻ റോഡ്. (ഏകദേശം 2 കി .മീ)\n",
            "\n",
            "7. കുണ്ടന്നൂർ പാലം മുറിച്ചുകടന്ന് നേരെ കൊച്ചി നഗരത്തിലേക്ക് പോകുക. (ഏകദേശം 2 കിലോമീറ്റർ)\n",
            "\n",
            "8. നിങ്ങൾ കൊച്ചി നഗരത്തിലെ എംജി റോഡിൽ എത്തും. കൊച്ചിയിൽ നിങ്ങളുടെ നിർദ്ദിഷ്ട ലക്ഷ്യസ്ഥാനത്ത് എത്തിച്ചേരുന്നതിന് അടയാളങ്ങൾ പാലിക്കുക.\n",
            "\n",
            "മൊത്തം ദൂരം: ഏകദേശം 155 കിലോമീറ്റർ\n",
            "\n",
            "ട്രാഫിക് കോ ശ്രദ്ധിക്കുക. nnditions ഉം റോഡ് വഴിതിരിച്ചുവിടലുകളും ഡ്രൈവിംഗ് സമയത്തെ ബാധിച്ചേക്കാം, അതിനാൽ നിങ്ങളുടെ യാത്ര ആരംഭിക്കുന്നതിന് മുമ്പ് ഏതെങ്കിലും തത്സമയ അപ്‌ഡേറ്റുകളോ ട്രാഫിക് അലേർട്ടുകളോ പരിശോധിക്കുന്നത് നല്ലതാണ്.\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from translate import Translator\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def detect_language(user_input):\n",
        "\n",
        "  if \"है\" in user_input:  # Simple check for Hindi character (replace with more robust logic)\n",
        "    return \"hi\"\n",
        "  elif \"ആണ്\" in user_input:  # Simple check for Malayalam character (replace with more robust logic)\n",
        "    return \"ml\"\n",
        "  else:\n",
        "    return \"en\"  # Assuming English by default\n",
        "\n",
        "def translate_text(text, target_language):\n",
        "  translator = Translator(to_lang=target_language)\n",
        "  return translator.translate(text)\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "  # Prompt for the OpenAI API (translated to English if needed)\n",
        "  user_language = detect_language(user_input)\n",
        "  if user_language != \"en\":\n",
        "    translated_prompt = translate_text(f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\", \"en\")\n",
        "    prompt = translated_prompt\n",
        "  else:\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message['content'].strip()\n",
        "\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description  # No translation needed if English is selected\n",
        "    elif target_language == 'ml':\n",
        "        return translate_to_malayalam(route_description)\n",
        "    else:\n",
        "        # Initialize translator\n",
        "        translator = Translator(to_lang=target_language)\n",
        "\n",
        "        sentences = route_description.split('. ')\n",
        "        translated_sentences = []\n",
        "\n",
        "        # Translate each sentence and join them back together\n",
        "        for sentence in sentences:\n",
        "            translated_sentence = translator.translate(sentence)\n",
        "            translated_sentences.append(translated_sentence)\n",
        "\n",
        "        translated_description = '. '.join(translated_sentences)\n",
        "\n",
        "        return translated_description\n",
        "\n",
        "def translate_to_malayalam(route_description):\n",
        "    # Initialize translator for Malayalam\n",
        "    translator = Translator(to_lang=\"ml\")\n",
        "\n",
        "    # Split route description into smaller chunks due to query length limitation\n",
        "    chunk_size = 300  # Adjust chunk size based on the API's limits\n",
        "    chunks = [route_description[i:i+chunk_size] for i in range(0, len(route_description), chunk_size)]\n",
        "\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        translated_chunk = translator.translate(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "\n",
        "    translated_description = '. '.join(translated_chunks)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    # Ask user for desired language for route description\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "kzd0r6pt2fHI",
        "outputId": "fa6a21ae-99ec-4176-97cb-990ba3991312"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-66-2476b9a26499>, line 17)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-2476b9a26499>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    for pattern in patterns:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from translate import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def detect_language(text):\n",
        "    # This function uses OpenAI's model to detect the language of the input text\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=f\"Detect the language of the following text:\\n\\n{text}\",\n",
        "        max_tokens=5\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def translate_to_english(text, source_language):\n",
        "    translator = Translator(from_lang=source_language, to_lang=\"en\")\n",
        "    return translator.translate(text)\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description  # No translation needed if English is selected\n",
        "    elif target_language == 'ml':\n",
        "        return translate_to_malayalam(route_description)\n",
        "    else:\n",
        "        # Initialize translator\n",
        "        translator = Translator(to_lang=target_language)\n",
        "\n",
        "        # Split route description into manageable chunks (e.g., sentences)\n",
        "        sentences = route_description.split('. ')\n",
        "        translated_sentences = []\n",
        "\n",
        "        # Translate each sentence and join them back together\n",
        "        for sentence in sentences:\n",
        "            translated_sentence = translator.translate(sentence)\n",
        "            translated_sentences.append(translated_sentence)\n",
        "\n",
        "        translated_description = '. '.join(translated_sentences)\n",
        "\n",
        "        return translated_description\n",
        "\n",
        "def translate_to_malayalam(route_description):\n",
        "    # Initialize translator for Malayalam\n",
        "    translator = Translator(to_lang=\"ml\")\n",
        "\n",
        "    # Split route description into smaller chunks due to query length limitation\n",
        "    chunk_size = 300  # Adjust chunk size based on the API's limits\n",
        "    chunks = [route_description[i:i+chunk_size] for i in range(0, len(route_description), chunk_size)]\n",
        "\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        translated_chunk = translator.translate(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "\n",
        "    translated_description = '. '.join(translated_chunks)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    detected_language = detect_language(user_input)\n",
        "    if detected_language in ['Hindi', 'Malayalam']:\n",
        "        user_input = translate_to_english(user_input, detected_language.lower())\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    # Ask user for desired language for route description\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "TQ1jQ8wo3K7S",
        "outputId": "c7aaa31a-130f-41b3-c152-507094ff462a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: തൃശൂർ മുതൽ കൊച്ചി വരെ\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "generator raised StopIteration",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/translate/translate.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRANSLATION_API_MAX_LENGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_wraped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_wraped\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/translate/providers/mymemory_translated.py\u001b[0m in \u001b[0;36mget_translation\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mnext_best_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext_best_match\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-440ae66712df>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mdetected_language\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_language\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdetected_language\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Hindi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Malayalam'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_to_english\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetected_language\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mstart_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-440ae66712df>\u001b[0m in \u001b[0;36mtranslate_to_english\u001b[0;34m(text, source_language)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate_to_english\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_language\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/translate/translate.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtext_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRANSLATION_API_MAX_LENGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_wraped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_wraped\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: generator raised StopIteration"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from translate import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \" \"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def detect_language(text):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=f\"Detect the language of the following text:\\n\\n{text}\",\n",
        "        max_tokens=5\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def translate_to_english(text, source_language):\n",
        "    translator = Translator(from_lang=source_language, to_lang=\"en\")\n",
        "    try:\n",
        "        return translator.translate(text)\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating to English: {e}\")\n",
        "        return text\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description\n",
        "    elif target_language == 'ml':\n",
        "        return translate_to_malayalam(route_description)\n",
        "    else:\n",
        "        translator = Translator(to_lang=target_language)\n",
        "\n",
        "        sentences = route_description.split('. ')\n",
        "        translated_sentences = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            try:\n",
        "                translated_sentence = translator.translate(sentence)\n",
        "                translated_sentences.append(translated_sentence)\n",
        "            except Exception as e:\n",
        "                print(f\"Error translating sentence: {e}\")\n",
        "                translated_sentences.append(sentence)\n",
        "\n",
        "        translated_description = '. '.join(translated_sentences)\n",
        "\n",
        "        return translated_description\n",
        "\n",
        "def translate_to_malayalam(route_description):\n",
        "    translator = Translator(to_lang=\"ml\")\n",
        "\n",
        "    chunk_size = 300\n",
        "    chunks = [route_description[i:i+chunk_size] for i in range(0, len(route_description), chunk_size)]\n",
        "\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        try:\n",
        "            translated_chunk = translator.translate(chunk)\n",
        "            translated_chunks.append(translated_chunk)\n",
        "        except Exception as e:\n",
        "            print(f\"Error translating chunk: {e}\")\n",
        "            translated_chunks.append(chunk)\n",
        "\n",
        "    translated_description = '. '.join(translated_chunks)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    detected_language = detect_language(user_input)\n",
        "    if detected_language.lower() in ['hindi', 'malayalam']:\n",
        "        user_input = translate_to_english(user_input, detected_language.lower())\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7QIg4Sq5W92",
        "outputId": "38026bcf-d301-47ed-c795-2eb84a26a9bc"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: തൃശൂർ മുതൽ കൊച്ചി വരെ\n",
            "Error translating to English: generator raised StopIteration\n",
            "Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\n",
            "Enter your request: തൃശൂർ മുതൽ കൊച്ചി വരെ\n",
            "Error translating to English: generator raised StopIteration\n",
            "Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LZwvCAi6z32",
        "outputId": "3b138a45-63be-4489-d49b-c38df51101e2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.6.2)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17395 sha256=a7f754f84eb1c3dc42a53c49d9dce229a8279d9b0c252b951bbc2fde1e71ebd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: googletrans\n",
            "  Attempting uninstall: googletrans\n",
            "    Found existing installation: googletrans 3.0.0\n",
            "    Uninstalling googletrans-3.0.0:\n",
            "      Successfully uninstalled googletrans-3.0.0\n",
            "Successfully installed googletrans-4.0.0rc1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from googletrans import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "def detect_language(text):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=f\"Detect the language of the following text:\\n\\n{text}\",\n",
        "        max_tokens=5\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def translate_to_english(text, source_language):\n",
        "    try:\n",
        "        translation = translator.translate(text, src=source_language, dest='en')\n",
        "        return translation.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating to English: {e}\")\n",
        "        return text\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description\n",
        "    else:\n",
        "        try:\n",
        "            translation = translator.translate(route_description, dest=target_language)\n",
        "            return translation.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error translating description: {e}\")\n",
        "            return route_description\n",
        "\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    detected_language = detect_language(user_input)\n",
        "    if detected_language.lower() in ['hindi', 'malayalam']:\n",
        "        user_input = translate_to_english(user_input, detected_language.lower())\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bvMBoPR62ap",
        "outputId": "bfbb58ac-f539-4535-fc88-10b2d779e074"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: തൃശൂർ മുതൽ കൊച്ചി വരെ\n",
            "Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H7ekCK4v-df6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wsG4XDkV67-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from translate import Translator\n",
        "from langdetect import detect  # For language detection\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def translate_to_english(user_input, source_language):\n",
        "    # Initialize translator for source language\n",
        "    translator = Translator(from_lang=source_language, to_lang=\"en\")\n",
        "    translated_input = translator.translate(user_input)\n",
        "    return translated_input\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description  # No translation needed if English is selected\n",
        "    elif target_language == 'ml':\n",
        "        return translate_to_malayalam(route_description)\n",
        "    elif target_language == 'hi':\n",
        "        return translate_to_hindi(route_description)\n",
        "    else:\n",
        "        # Initialize translator\n",
        "        translator = Translator(to_lang=target_language)\n",
        "\n",
        "        # Split route description into manageable chunks (e.g., sentences)\n",
        "        sentences = route_description.split('. ')\n",
        "        translated_sentences = []\n",
        "\n",
        "        # Translate each sentence and join them back together\n",
        "        for sentence in sentences:\n",
        "            translated_sentence = translator.translate(sentence)\n",
        "            translated_sentences.append(translated_sentence)\n",
        "\n",
        "        translated_description = '. '.join(translated_sentences)\n",
        "\n",
        "        return translated_description\n",
        "\n",
        "def translate_to_malayalam(route_description):\n",
        "    # Initialize translator for Malayalam\n",
        "    translator = Translator(to_lang=\"ml\")\n",
        "\n",
        "    # Split route description into smaller chunks due to query length limitation\n",
        "    chunk_size = 300  # Adjust chunk size based on the API's limits\n",
        "    chunks = [route_description[i:i+chunk_size] for i in range(0, len(route_description), chunk_size)]\n",
        "\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        translated_chunk = translator.translate(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "\n",
        "    translated_description = '. '.join(translated_chunks)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "def translate_to_hindi(route_description):\n",
        "    # Initialize translator for Hindi\n",
        "    translator = Translator(to_lang=\"hi\")\n",
        "\n",
        "    # Split route description into smaller chunks due to query length limitation\n",
        "    chunk_size = 300  # Adjust chunk size based on the API's limits\n",
        "    chunks = [route_description[i:i+chunk_size] for i in range(0, len(route_description), chunk_size)]\n",
        "\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        translated_chunk = translator.translate(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "\n",
        "    translated_description = '. '.join(translated_chunks)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request in Malayalam (മലയാളം) or Hindi (हिन्दी): \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    # Detect the language of user input\n",
        "    try:\n",
        "        user_language = detect(user_input)\n",
        "    except:\n",
        "        print(\"Language detection failed. Please enter your request in Malayalam (മലയാളം) or Hindi (हिन्दी).\")\n",
        "        continue\n",
        "\n",
        "    # Translate the user input to English for processing\n",
        "    translated_input = translate_to_english(user_input, user_language)\n",
        "\n",
        "    start_location, end_location = extract_locations(translated_input)\n",
        "\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    # Ask user for desired language for route description\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "TwcXlea_a21n",
        "outputId": "2619bff2-45ed-4d34-9ca4-399102874dda"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request in Malayalam (മലയാളം) or Hindi (हिन्दी): തൃശൂർ മുതൽ കൊച്ചി വരെ\n",
            "Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-666d01ec2e5f>\u001b[0m in \u001b[0;36m<cell line: 107>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your request in Malayalam (മലയാളം) or Hindi (हिन्दी): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from translate import Translator\n",
        "from langdetect import detect\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] =\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description\n",
        "    elif target_language == 'ml':\n",
        "        return translate_to_malayalam(route_description)\n",
        "    elif target_language == 'hi':\n",
        "        return translate_to_hindi(route_description)\n",
        "    else:\n",
        "\n",
        "        translator = Translator(to_lang=target_language)\n",
        "\n",
        "        sentences = route_description.split('. ')\n",
        "        translated_sentences = []\n",
        "\n",
        "\n",
        "        for sentence in sentences:\n",
        "            translated_sentence = translator.translate(sentence)\n",
        "            translated_sentences.append(translated_sentence)\n",
        "\n",
        "        translated_description = '. '.join(translated_sentences)\n",
        "\n",
        "        return translated_description\n",
        "\n",
        "def translate_to_malayalam(route_description):\n",
        "\n",
        "    translator = Translator(to_lang=\"ml\")\n",
        "\n",
        "\n",
        "    chunk_size = 300\n",
        "    chunks = [route_description[i:i+chunk_size] for i in range(0, len(route_description), chunk_size)]\n",
        "\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        translated_chunk = translator.translate(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "\n",
        "    translated_description = '. '.join(translated_chunks)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "def translate_to_hindi(route_description):\n",
        "\n",
        "    translator = Translator(to_lang=\"hi\")\n",
        "\n",
        "\n",
        "    chunk_size = 300\n",
        "    chunks = [route_description[i:i+chunk_size] for i in range(0, len(route_description), chunk_size)]\n",
        "\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        translated_chunk = translator.translate(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "\n",
        "    translated_description = '. '.join(translated_chunks)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "\n",
        "    try:\n",
        "        user_language = detect(user_input)\n",
        "    except:\n",
        "        print(\"Language detection failed. Please enter your request in Malayalam (മലയാളം) or Hindi (हिन्दी).\")\n",
        "        continue\n",
        "\n",
        "    if user_language == 'ml':\n",
        "        user_input = translate_to_english(user_input, 'ml')\n",
        "    elif user_language == 'hi':\n",
        "        user_input = translate_to_english(user_input, 'hi')\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "s8iCDks4ZjzA",
        "outputId": "707ff99d-7e9e-4121-c209-b279c25efc66"
      },
      "execution_count": 59,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: തൃശൂർ മുതൽ കൊച്ചി വരെ\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'translate_to_english' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-1057ef098543>\u001b[0m in \u001b[0;36m<cell line: 101>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_language\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ml'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_to_english\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0muser_language\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'hi'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_to_english\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'translate_to_english' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from translate import Translator\n",
        "from langdetect import detect  # For language detection\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description  # No translation needed if English is selected\n",
        "    elif target_language == 'ml':\n",
        "        return translate_to_malayalam(route_description)\n",
        "    elif target_language == 'hi':\n",
        "        return translate_to_hindi(route_description)\n",
        "    else:\n",
        "        # Initialize translator\n",
        "        translator = Translator(to_lang=target_language)\n",
        "\n",
        "        # Split route description into manageable chunks (e.g., sentences)\n",
        "        sentences = route_description.split('. ')\n",
        "        translated_sentences = []\n",
        "\n",
        "        # Translate each sentence and join them back together\n",
        "        for sentence in sentences:\n",
        "            translated_sentence = translator.translate(sentence)\n",
        "            translated_sentences.append(translated_sentence)\n",
        "\n",
        "        translated_description = '. '.join(translated_sentences)\n",
        "\n",
        "        return translated_description\n",
        "\n",
        "def translate_to_malayalam(route_description):\n",
        "    # Initialize translator for Malayalam\n",
        "    translator = Translator(to_lang=\"ml\")\n",
        "\n",
        "    # Split route description into smaller chunks due to query length limitation\n",
        "    chunk_size = 300  # Adjust chunk size based on the API's limits\n",
        "    chunks = [route_description[i:i+chunk_size] for i in range(0, len(route_description), chunk_size)]\n",
        "\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        translated_chunk = translator.translate(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "\n",
        "    translated_description = '. '.join(translated_chunks)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "def translate_to_hindi(route_description):\n",
        "    # Initialize translator for Hindi\n",
        "    translator = Translator(to_lang=\"hi\")\n",
        "\n",
        "    # Split route description into smaller chunks due to query length limitation\n",
        "    chunk_size = 300  # Adjust chunk size based on the API's limits\n",
        "    chunks = [route_description[i:i+chunk_size] for i in range(0, len(route_description), chunk_size)]\n",
        "\n",
        "    translated_chunks = []\n",
        "    for chunk in chunks:\n",
        "        translated_chunk = translator.translate(chunk)\n",
        "        translated_chunks.append(translated_chunk)\n",
        "\n",
        "    translated_description = '. '.join(translated_chunks)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    # Detect the language of user input\n",
        "    try:\n",
        "        user_language = detect(user_input)\n",
        "    except:\n",
        "        print(\"Language detection failed. Please enter your request in Malayalam (മലയാളം) or Hindi (हिन्दी).\")\n",
        "        continue\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    # Ask user for desired language for route description\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMwji6KyaEWZ",
        "outputId": "daa904da-0f75-4b23-d49e-fbb3d81fcdbe"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: തൃശൂർ മുതൽ കൊച്ചി വരെ\n",
            "Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\n",
            "Enter your request: from thrissur to kochi\n",
            "Route Description (in English): Here is a detailed driving route from Thrissur to Kochi:\n",
            "\n",
            "1. Start in Thrissur and head south on SH 22 (Shoranur - Thrissur Highway) towards Muttikkal - 0 km\n",
            "2. Continue on the same road for about 10 km until you reach Palakkad Road - 10 km\n",
            "3. Take a left onto Palakkad Road and continue for about 9 km\n",
            "4. At the roundabout, take the 2nd exit onto NH 544 (Thrissur - Kochi Highway) - 19 km\n",
            "5. Continue on NH 544 for about 40 km until you reach Angamaly - 59 km\n",
            "6. At Angamaly, take the NH 966A towards Kochi - 60 km\n",
            "7. Continue on NH 966A for about 18 km until you reach the outskirts of Kochi - 78 km\n",
            "8. Follow the signs to your specific destination within Kochi or use GPS navigation for final directions to your destination\n",
            "\n",
            "Landmarks along the way:\n",
            "- Palakkad Road junction\n",
            "- Angamaly town\n",
            "- Edappally junction (entry point to Kochi city)\n",
            "\n",
            "Please note that the distances mentioned are approximate and may vary slightly based on actual road conditions and traffic. Drive safely and enjoy your journey from Thrissur to Kochi!\n",
            "Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): ml'\n",
            "Route Description (in ml'): 'ML'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT. 'ML'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT. 'ML'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT. 'ML'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT. 'ML'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT. 'ML'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT. 'ML'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT. 'ML'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT. 'ML'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT. 'ML'' IS AN INVALID TARGET LANGUAGE . EXAMPLE: LANGPAIR=EN|IT USING 2 LETTER ISO OR RFC3066 LIKE ZH-CN. ALMOST ALL LANGUAGES SUPPORTED BUT SOME MAY HAVE NO CONTENT\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THHsaG2ZZnRo",
        "outputId": "e61438d7-38bb-43e1-dd89-ae4162d910c6"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/981.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=52de7c424b09b00e2d2fb97f001a37ed7e327c578d7a16c3b8b3d84172d75a25\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxYUSihCKohw",
        "outputId": "c8dc03d1-92ff-4f4a-8179-6af2d48e4284"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Set up the MarianMT model and tokenizer\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-es'  # English to Spanish translation\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location, target_language='es'):\n",
        "    # Prompt for the model\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    inputs = tokenizer.prepare_seq2seq_batch(src_texts=[prompt], return_tensors=\"pt\")\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs)\n",
        "\n",
        "    # Decode and convert response tensor to text\n",
        "    translated_description = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    # Generate route description in Spanish\n",
        "    route_description = generate_route_description(start_location, end_location, target_language='es')\n",
        "    print(\"Route Description (in Spanish):\", route_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712,
          "referenced_widgets": [
            "fed7ae8e7e5648ec81acfe9a421ca865",
            "185b5cd3d47c48c296a82a6d3e21d706",
            "42fe71cda2524e2987b21894bb24b29d",
            "08ef3b94581c4b6a9adac18d8720e521",
            "d7ecbc3f757b4543a673a2a02f59d680",
            "2b9fdfd9997e44dcb3023ad1ce3b777b",
            "a681840cb5fb40c7844504f2b3d325e4",
            "20e10121897b4d088096329ab6f3b411",
            "292f483c03d6462ba7f7ab098ea0e8c3",
            "8648ad6c9d54472d8960e26f9da49d5c",
            "e4a7ea7a444d48bf986f71350e870479",
            "e40e480c09124aa2a6a052aa21e61b0c",
            "c6ce6f0591d248e28877d48223adc373",
            "0d9fdb73d88f42b5842b8bb6bf43580e",
            "44c60135c74e42059f210785343f8dc3",
            "7f6f3016273b4e799ed3751ac6067397",
            "09c4be25eebf4f57a8fa42d40c904405",
            "088caf8cb4bb47288a5973b604cd512c",
            "95fb6cc4c7554c069c64dc38b98b3e50",
            "9d87564398394e8e96323dddafe00a77",
            "64a8a32fc0bc42f4b4bf5fcceb8406a9",
            "648d871aa8b649d59e7900e313780393",
            "c17f6b80259e4af4a8c241075428e8a9",
            "dcf20b8cc39f41ae87a7764a2fcf09c6",
            "c7b8fe61780d430190febc2001623c78",
            "7657ca8154294247ac80d1f7287461b1",
            "e1c8faba0b7942d59d234b8d9c81c709",
            "ca151bea3e0a44648259f874e5b15260",
            "4c974510a3bf4e91a8f427bdca7583b8",
            "56320f75e1884e518ea1ea10c00c3e03",
            "a4a2fb271f5142289ba3fa81ec1e3594",
            "52f807c61f234860abe369adc7bad027",
            "3f6e94defd1d4c2ab7f1931c0f288ae4",
            "3d7f552f20d0481eba8e25b1bcbbb256",
            "bfc9ca63dbbb44aab2858a7fa1673623",
            "911df1aed42c48f0a52a3b6163ad169c",
            "6940d3b033564983bdfa6a3e0f4ea5a7",
            "aefae107b3504b5a99a7715a685c5507",
            "a39bff61df244f20834ce926f59d7a7c",
            "37eaad29183a4f7a896482f5bff94322",
            "1dfd50e84f064de8b050a3d765b43151",
            "ba0bd5b6de32479983b70a781497220c",
            "4238146d3af54b6bb213602069c1c645",
            "b49bbb4de33d43118a714d50904e76bb",
            "6c7105ac96f843e980e1549d8121f4d9",
            "9bba7815761c44d2afe3a6ed0a309c66",
            "30faeda985e9436aa10027b821bd3d01",
            "c584fe3f6af3499ebe9016e203eec1f4",
            "9df6854621fc423ba62d9b7eee68516b",
            "752de6d5ccb14566a43fb6758aa3ab9b",
            "d06ac9559f864a6d806cecc62c140549",
            "d1040f150de547a7836b006fbf43546f",
            "dd774469248240abb0e8b97b472804c3",
            "a386a585f7ce45329948a82a18e7eca9",
            "c60bde2cac064d749108bb0332cfd6ae",
            "3fa0bb2b8c6246deaaf4bb56beef33b3",
            "fba990f873084c7c82727ba389640058",
            "6cc9a68659e9402aa3900e436358ca65",
            "dae3d1d7d1d14bd7a5f22bdc9b5aa01d",
            "04f115973dc44e2dbba731a316ec7365",
            "e368c7c1a24c454fb322dd05fc1f096b",
            "dbbcaff7fd354c14b07f6d8ebcd4b923",
            "cc2d1c0f2d9945008c8f5eb1507e8712",
            "e60e036bec254630ba16c87f1c5da35c",
            "00d5dba3a0a640bfa10b1155b29d54f8",
            "48f2e82fa8774da09f0c09632ad83f98",
            "d4097130e6f747fc8e420668e07a15eb",
            "f3d350965d61428287f06bc54d0c5061",
            "c0397a675729495b9369773f300e7abd",
            "86fdae826eeb461c9b529853cf47331f",
            "f7e46ae7ed5f4c389622caa430fbb1bd",
            "ad372e01b4df487fac0dd6c677c1fa9b",
            "83262a5215b24168b36654474250fc2d",
            "cf34143a108e4a30b8da465a4df0743d",
            "93ce53003f3c438884bc80c1d39e2bf5",
            "0a5985453560408c9bb01e164403f259",
            "e2413c2fa0334f98a5a514fe1009d61a"
          ]
        },
        "id": "31W2vPQ1LAkl",
        "outputId": "cdb73ebf-a955-4266-90c4-e0193ae61a25"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fed7ae8e7e5648ec81acfe9a421ca865"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e40e480c09124aa2a6a052aa21e61b0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c17f6b80259e4af4a8c241075428e8a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d7f552f20d0481eba8e25b1bcbbb256"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c7105ac96f843e980e1549d8121f4d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/826k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fa0bb2b8c6246deaaf4bb56beef33b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4097130e6f747fc8e420668e07a15eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: take me from kannur to kozhikode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4072: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Route Description (in Spanish): Proveer una ruta de conducción detallada de Kannur a kozhikode. Incluye grandes giros, puntos de referencia y distancias.\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eXghRk4LsRd",
        "outputId": "74da949a-7f76-4cca-f113-5ea3df687ed0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: take me from kannur to kozhikode\n",
            "Route Description (in Spanish): QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS अपनी यात्रा के दौरान रीयल - टाइम अपडेट और दिशा - निर्देश पाने के लिए नेविगेशन ऐप का इस्तेमाल करने की सलाह दी जाती है।\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import openai\n",
        "from translate import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def ask_language():\n",
        "    while True:\n",
        "        print(\"In which language would you like the route description?\")\n",
        "        print(\"1. English\")\n",
        "        print(\"2. Spanish\")\n",
        "        print(\"3. Hindi\")\n",
        "        choice = input(\"Enter the number corresponding to your choice (1/2/3): \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            return 'en'\n",
        "        elif choice == '2':\n",
        "            return 'es'\n",
        "        elif choice == '3':\n",
        "            return 'hi'\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
        "\n",
        "def generate_route_description(start_location, end_location, target_language='en'):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    # Generate response from OpenAI\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    route_description = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Translate the route description to the target language if needed\n",
        "    if target_language != 'en':\n",
        "        translator = Translator(to_lang=target_language)\n",
        "        translated_description = translator.translate(route_description)\n",
        "    else:\n",
        "        translated_description = route_description\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    target_language = ask_language()\n",
        "    route_description = generate_route_description(start_location, end_location, target_language)\n",
        "\n",
        "    language_name = {\n",
        "        'en': 'English',\n",
        "        'es': 'Spanish',\n",
        "        'hi': 'Hindi'\n",
        "    }.get(target_language, 'Unknown')\n",
        "\n",
        "    print(f\"Route Description (in {language_name}):\", route_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvK2ht7MMQSH",
        "outputId": "7bea4541-121f-4f7b-9ef5-f2f3e19405fb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from kannur to kozhikode\n",
            "In which language would you like the route description?\n",
            "1. English\n",
            "2. Spanish\n",
            "3. Hindi\n",
            "Enter the number corresponding to your choice (1/2/3): 1\n",
            "Route Description (in English): The driving route from Kannur to Kozhikode is approximately 90 kilometers long, and here is a detailed guide with major turns, landmarks, and distances:\n",
            "\n",
            "1. Start from Kannur and head south on NH 66 (also known as Kochi - Panvel Highway).\n",
            "2. After approximately 10 kilometers, you will pass by Thottada Beach on your left.\n",
            "3. Continue on NH 66 for another 15 kilometers until you reach Thalassery.\n",
            "4. Pass through Thalassery town and continue on NH 66.\n",
            "5. After around 35 kilometers from Kannur, you will reach Mahe town.\n",
            "6. Continue on NH 66 for another 15 kilometers, passing by Vadakara town.\n",
            "7. After around 15 kilometers from Vadakara, you will reach Kozhikode city.\n",
            "8. Follow the signs towards Kozhikode city center or your specific destination within Kozhikode.\n",
            "\n",
            "Landmarks and notable points along the route:\n",
            "- Thottada Beach\n",
            "- Thalassery town\n",
            "- Mahe town\n",
            "- Vadakara town\n",
            "\n",
            "Please note that the driving time may vary depending on traffic conditions and your driving speed. It is recommended to use a navigation app for real-time updates and accurate directions during the journey.\n",
            "Enter your request: from thrissur to kochi\n",
            "In which language would you like the route description?\n",
            "1. English\n",
            "2. Spanish\n",
            "3. Hindi\n",
            "Enter the number corresponding to your choice (1/2/3): 3\n",
            "Route Description (in Hindi): QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS कोच्चि में आपका खास डेस्टिनेशन।\n",
            "\n",
            "त्रिशूर से कोच्चि की कुल दूरी लगभग 80 किमी है, और यातायात की स्थिति के आधार पर अनुमानित ड्राइविंग समय लगभग 2 घंटे है। आसानी से नेविगेट करने के लिए रास्ते में साइनबोर्ड और लैंडमार्क का पालन करना न भूलें।\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import openai\n",
        "from translate import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location, target_language='en'):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    # Generate response from OpenAI using the chat completion endpoint\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    route_description = response.choices[0].message['content'].strip()\n",
        "\n",
        "    # Translate the route description to the target language if needed\n",
        "    if target_language != 'en':\n",
        "        translator = Translator(to_lang=target_language)\n",
        "        translated_description = translator.translate(route_description)\n",
        "    else:\n",
        "        translated_description = route_description\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    # Example: Translating to Malayalam ('ml'). You can change 'ml' to any other language code as needed.\n",
        "    route_description = generate_route_description(start_location, end_location, target_language='ml')\n",
        "\n",
        "    language_name = {\n",
        "        'en': 'English',\n",
        "        'ml': 'Malayalam'\n",
        "    }.get('ml', 'Unknown')\n",
        "\n",
        "    print(f\"Route Description (in {language_name}): {route_description}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iiJYuCNM2rI",
        "outputId": "e5818c19-97a6-4b54-9f70-fddf171b158f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from thrissur to kochi\n",
            "Route Description (in Malayalam): QUERY LENGTH LIMIT EXCEEDED. MAX ALLOWED QUERY : 500 CHARS ദൂരം:\n",
            "നഗരങ്ങളിലെ നിങ്ങളുടെ നിർദ്ദിഷ്ട ആരംഭ, അവസാന പോയിന്റുകളെ ആശ്രയിച്ച് തൃശ്ശൂരിൽ നിന്ന് കൊച്ചിയിലേക്കുള്ള മൊത്തം ഡ്രൈവിംഗ് ദൂരം ഏകദേശം 80-90 കിലോമീറ്ററാണ്.\n",
            "\n",
            "റോഡ് അവസ്ഥകളും ട്രാഫിക്കും വ്യത്യാസപ്പെടാമെന്നത് ശ്രദ്ധിക്കുക, അതിനാൽ നിങ്ങളുടെ യാത്രയ്ക്കിടെ തത്സമയ അപ്‌ഡേറ്റുകൾക്കായി ഒരു നാവിഗേഷൻ ആപ്പ് ഉപയോഗിക്കുന്നത് നല്ലതാണ്.\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from translate import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key if needed)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "# Uncomment below line if it's needed\n",
        "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Function to extract locations from user input\n",
        "def extract_locations(user_input):\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "# Function to generate route description using IndicCorp model\n",
        "def generate_route_description(start_location, end_location, target_language='en'):\n",
        "    # Initialize tokenizer and model for IndicCorp\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indic-bert\")\n",
        "\n",
        "    # Prepare inputs and encode them\n",
        "    inputs = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "    input_ids = tokenizer.encode(inputs, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    # Generate response from IndicCorp\n",
        "    translator = Translator(to_lang=target_language)\n",
        "    route_description = translator.translate(inputs)\n",
        "\n",
        "    return route_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    # Example: Translating to Hindi ('hi'). You can change 'hi' to any other language code as needed.\n",
        "    route_description = generate_route_description(start_location, end_location, target_language='hi')\n",
        "\n",
        "    language_name = {\n",
        "        'en': 'English',\n",
        "        'hi': 'Hindi'\n",
        "        # Add more languages as needed\n",
        "    }.get('hi', 'Unknown')\n",
        "\n",
        "    print(f\"Route Description (in {language_name}): {route_description}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "V41IseUOQryj",
        "outputId": "2ec1b2e2-49f2-498f-873e-d53bfce4b238"
      },
      "execution_count": 49,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from kannur to kozhikode\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized configuration class <class 'transformers.models.albert.configuration_albert.AlbertConfig'> for this kind of AutoModel: AutoModelForSeq2SeqLM.\nModel type should be one of BartConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, EncoderDecoderConfig, FSMTConfig, GPTSanJapaneseConfig, LEDConfig, LongT5Config, M2M100Config, MarianConfig, MBartConfig, MT5Config, MvpConfig, NllbMoeConfig, PegasusConfig, PegasusXConfig, PLBartConfig, ProphetNetConfig, SeamlessM4TConfig, SeamlessM4Tv2Config, SwitchTransformersConfig, T5Config, UMT5Config, XLMProphetNetConfig.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-0e5a2459b552>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Example: Translating to Hindi ('hi'). You can change 'hi' to any other language code as needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mroute_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_route_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     language_name = {\n",
            "\u001b[0;32m<ipython-input-49-0e5a2459b552>\u001b[0m in \u001b[0;36mgenerate_route_description\u001b[0;34m(start_location, end_location, target_language)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Initialize tokenizer and model for IndicCorp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ai4bharat/indic-bert\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ai4bharat/indic-bert\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Prepare inputs and encode them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             )\n\u001b[0;32m--> 566\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;34mf\"Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.albert.configuration_albert.AlbertConfig'> for this kind of AutoModel: AutoModelForSeq2SeqLM.\nModel type should be one of BartConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, EncoderDecoderConfig, FSMTConfig, GPTSanJapaneseConfig, LEDConfig, LongT5Config, M2M100Config, MarianConfig, MBartConfig, MT5Config, MvpConfig, NllbMoeConfig, PegasusConfig, PegasusXConfig, PLBartConfig, ProphetNetConfig, SeamlessM4TConfig, SeamlessM4Tv2Config, SwitchTransformersConfig, T5Config, UMT5Config, XLMProphetNetConfig."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Function to extract locations from user input\n",
        "def extract_locations(user_input):\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "# Function to generate route description using facebook bart multilingual\n",
        "def generate_route_description(start_location, end_location, target_language='en'):\n",
        "  # Initialize tokenizer and model for facebook bart multilingual\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base-multilingual\")\n",
        "  model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-base-multilingual\")\n",
        "\n",
        "\n",
        "  inputs = f\"Provide a detailed driving route from {start_location} to {end_location} in English. Include major turns, landmarks, and distances.\"\n",
        "  input_ids = tokenizer(inputs, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "  # Generate response from the model\n",
        "  output = model.generate(**input_ids)\n",
        "  route_description = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
        "\n",
        "  # Translate the route description if needed\n",
        "  if target_language != 'en':\n",
        "    translator = pipeline(\"translation\", model=\"facebook/bart-base-multilingual\")\n",
        "    translated_route_description = translator(route_description, source_language=\"en\", target_language=target_language)[0][\"translation_text\"]\n",
        "    return translated_route_description\n",
        "  else:\n",
        "    return route_description\n",
        "\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    # Example: Translating to Hindi ('hi'). You can change 'hi' to any other language code as needed.\n",
        "    route_description = generate_route_description(start_location, end_location, target_language='hi')\n",
        "\n",
        "    language_name = {\n",
        "        'en': 'English',\n",
        "        'hi': 'Hindi'\n",
        "        # Add more languages as needed\n",
        "    }.get('hi', 'Unknown')\n",
        "\n",
        "    print(f\"Route Description (in {language_name}): {route_description}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "zUz7CizvRgLB",
        "outputId": "e83dfad7-ea06-40f4-8449-0299b546f705"
      },
      "execution_count": 50,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from kannur to kozhikode\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "facebook/bart-base-multilingual is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/facebook/bart-base-multilingual/resolve/main/tokenizer_config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hf_file_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1646\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-6673c875-55701ee83a774ed87b8e0c50;9fa156a6-fead-4b2d-b16b-80b016febfd5)\n\nRepository Not Found for url: https://huggingface.co/facebook/bart-base-multilingual/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-81a01639c45a>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Example: Translating to Hindi ('hi'). You can change 'hi' to any other language code as needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mroute_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_route_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     language_name = {\n",
            "\u001b[0;32m<ipython-input-50-81a01639c45a>\u001b[0m in \u001b[0;36mgenerate_route_description\u001b[0;34m(start_location, end_location, target_language)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_route_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;31m# Initialize tokenizer and model for facebook bart multilingual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/bart-base-multilingual\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/bart-base-multilingual\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         ) from e\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: facebook/bart-base-multilingual is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key if needed)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "# Uncomment below line if it's needed\n",
        "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Function to extract locations from user input\n",
        "def extract_locations(user_input):\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "# Function to generate route description using Helsinki model\n",
        "def generate_route_description(start_location, end_location, target_language='en'):\n",
        "    # Initialize tokenizer and model for Helsinki model (MarianMT)\n",
        "    model_name = f'Helsinki-NLP/opus-mt-en-hi'\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Prepare inputs and encode them\n",
        "    inputs = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "    inputs = tokenizer.prepare_seq2seq_batch([inputs], return_tensors='pt')\n",
        "\n",
        "    # Generate response from Helsinki model\n",
        "    translated_ids = model.generate(**inputs)\n",
        "    route_description = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return route_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    # Generate initial route description in English\n",
        "    route_description = generate_route_description(start_location, end_location, target_language='en')\n",
        "    print(f\"Route Description (in English): {route_description}\")\n",
        "\n",
        "    # Ask user if they want the description in another language\n",
        "    while True:\n",
        "        user_choice = input(\"Do you want the description in another language? (y/n): \").lower()\n",
        "        if user_choice == 'y':\n",
        "            print(\"Available languages: Hindi (hi), Bengali (bn), Tamil (ta), Telugu (te), Marathi (mr), Gujarati (gu), Kannada (kn), Malayalam (ml), Punjabi (pa), Odia (or)\")\n",
        "            target_language = input(\"Enter the language code (e.g., 'hi' for Hindi): \").strip().lower()\n",
        "            # Ensure valid language code and translate if needed\n",
        "            if target_language in ['en', 'hi', 'bn', 'ta', 'te', 'mr', 'gu', 'kn', 'ml', 'pa', 'or']:  # Add more languages as needed\n",
        "                route_description = generate_route_description(start_location, end_location, target_language=target_language)\n",
        "                language_name = {\n",
        "                    'en': 'English',\n",
        "                    'hi': 'Hindi',\n",
        "                    'bn': 'Bengali',\n",
        "                    'ta': 'Tamil',\n",
        "                    'te': 'Telugu',\n",
        "                    'mr': 'Marathi',\n",
        "                    'gu': 'Gujarati',\n",
        "                    'kn': 'Kannada',\n",
        "                    'ml': 'Malayalam',\n",
        "                    'pa': 'Punjabi',\n",
        "                    'or': 'Odia'\n",
        "                    # Add more languages as needed\n",
        "                }.get(target_language, 'Unknown')\n",
        "                print(f\"Route Description (in {language_name}): {route_description}\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Unsupported language. Please try again.\")\n",
        "        elif user_choice == 'n':\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter 'y' or 'n'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9130cfffd26b4578a63c7837287d85c2",
            "ecaa66522ba14cd492adc15f56446187",
            "72ea4d65324643459f706c5c55eb9596",
            "b22b9e6e37564a24b0ca71ecfc25df51",
            "be51bafb71534752b787b7f78ffe01a3",
            "4dc43207c7a541aaa2e82c133ac94458",
            "d6bb57ed9dc841e48c532a96c4ecca85",
            "52a64e713f2a4ae2bbeebe3e7492ce58",
            "99a3a00817fe4b2ebaf06a61cbe69947",
            "ce2e233894a148fb8669f7ec61c33f61",
            "b6522f91060048c98294dc5e8fc85d5d",
            "5e0637399b0c42ce89c8caa041204c74",
            "659e4544c1e148fd9a5990b78a95166a",
            "a88204d28a644425a054e06a9d3efc38",
            "7647447768bf49d7b2c051619a9a9478",
            "043085c9d93e4bb786292dbec960a1d9",
            "98b3b04f7e324f0882ab88d9fcc30b52",
            "c09b4af8cd7048deaa43214a917fe73d",
            "9a0f60fdacf2481a922c35d08147d2e2",
            "3715327e488949e9a1c3fb8110d5052b",
            "b9f9536b5e3349d99eedecf60cfae3ea",
            "4db58389d81244f0a0b39398cc1579f6",
            "c86788ca4d744f98a33e1e0559a3d329",
            "18f0045912b948dba6f1593d6534e686",
            "f8df02a629ad466e9072edd38a72decc",
            "842939e804644c66be1fed94bf669287",
            "651d4af14e3a48f09ffc9b42c1d6a27c",
            "dd810388ff814345937c73ec08ef94b3",
            "c9f8985c290b4d1a9cf67d918a8c7160",
            "b58fc8fca29c47eb8a9b96ce17f809cb",
            "f15362919383423d983b98b2445c17b9",
            "b7757a076fea4ce9a05dad92d43ff5bc",
            "130d88d1c2ac4b5b92aae4620a535ca9",
            "70f5183218444b37b2ede00aa2d60f67",
            "c3a4ea3023fb4780be0b3a96299ef2d5",
            "ea8ff39ae7b344edb89f9c7b85a917b4",
            "03b77f429c904db7917dbc437788433d",
            "565eea2c2ca7411d9c7c945a379dca83",
            "4c7ea5c20149422c93f113796a15903d",
            "e577175a851746efb10c7574cc8e107d",
            "5c39985c444943e0b4a9c92efba184a1",
            "dd2088e1945e4b648e357e4835b07480",
            "781bf6e433c649c3b4582dcf2f9f458f",
            "a587c616f354413392a31ef5d217ef55",
            "7a5972eb31164689a01ab9b4cab32a21",
            "39bfdec49ae14084acaddef206257f32",
            "1782a1a9b9d74c1097112720a286a00d",
            "f49f779a2d314261b54273359b63f25e",
            "e7891eb234b7416eaac2cfe6a164d0ed",
            "32097bb682a74612b8c24544f4729b72",
            "6bca69362b6f4dbf8ac8645e74bac564",
            "733985f895fd4841ab6d6881a841e1f2",
            "bc4f271d78ff4d40bc460db55453ccb6",
            "29039792787f48af91e643d0131affe3",
            "9514b291acc54ccdb6f226d509102d4f",
            "62b85b1aadee4555a818e489e74fa3a5",
            "dccacfb7d30a4a27a13b0590719fee17",
            "04c7f3e142a04ed5aef97537c6a7039e",
            "ffb92f8daff84bba8a09914ea75dda27",
            "dd22b645880d4aac9028c275d9acccae",
            "422de2ff75c045b88503dac21ef60bb9",
            "9532c99572a8426dbb3813b0c9a10edc",
            "2e17ae35ec1a46a8a85d468df162a877",
            "d3bd7361c15749cebb66cf962f498124",
            "fa3b65f5668c4158851191edf80891e0",
            "0638baa5e3064615bf793f37854d5da5",
            "dae7735a9f2942b7a227cd69ff88a0d4",
            "8ec636d601a4457a80711c91a004e849",
            "0dc47d36d2544b4c8908b82e27b5b0d4",
            "bb7045de46e847bf847383ef6411520d",
            "66a4c4c60d43465a82501b843d0e92df",
            "b1bf21b786fe45f2b509faf3a7315702",
            "81be804ab91c40b4bde859166f723532",
            "8f1d5f06152f43b798ede48ebcdc4386",
            "2190203e4ced46469b5c86e383df37fa",
            "9a7724f11927489d8f159439265df18b",
            "261e32c13eda47d3b328f63c6b313dad"
          ]
        },
        "id": "aVBwtXZMSd-9",
        "outputId": "4c3b5810-9a90-41dc-d683-c04be4caf7b7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from kannur to kozhikode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9130cfffd26b4578a63c7837287d85c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/306M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e0637399b0c42ce89c8caa041204c74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c86788ca4d744f98a33e1e0559a3d329"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70f5183218444b37b2ede00aa2d60f67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a5972eb31164689a01ab9b4cab32a21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62b85b1aadee4555a818e489e74fa3a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dae7735a9f2942b7a227cd69ff88a0d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4072: FutureWarning: \n",
            "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
            "`__call__` method to prepare your inputs and targets.\n",
            "\n",
            "Here is a short example:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
            "\n",
            "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
            "this:\n",
            "\n",
            "model_inputs = tokenizer(src_texts, ...)\n",
            "labels = tokenizer(text_target=tgt_texts, ...)\n",
            "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
            "\n",
            "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
            "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
            "\n",
            "  warnings.warn(formatted_warning, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Route Description (in English): कोर से कोर तक एक विस्तृत गाड़ी मार्ग प्रदान करें ।\n",
            "Do you want the description in another language? (y/n): y\n",
            "Available languages: Hindi (hi), Bengali (bn), Tamil (ta), Telugu (te), Marathi (mr), Gujarati (gu), Kannada (kn), Malayalam (ml), Punjabi (pa), Odia (or)\n",
            "Enter the language code (e.g., 'hi' for Hindi): hi\n",
            "Route Description (in Hindi): कोर से कोर तक एक विस्तृत गाड़ी मार्ग प्रदान करें ।\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-b46dabc92728>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your request: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Exiting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import openai\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location, target_language='en'):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    # Generate response from OpenAI using AI-4 India's multilingual model\n",
        "    response = openai.Completion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # AI-4 India's multilingual model\n",
        "        prompt=prompt,\n",
        "        max_tokens=1000,  # Adjust as needed\n",
        "        stop=[\"\\n\"]\n",
        "    )\n",
        "    route_description = response.choices[0].text.strip()\n",
        "\n",
        "    return route_description\n",
        "\n",
        "# Function to ask user for language choice\n",
        "def ask_language():\n",
        "    print(\"Please choose the language for the route description:\")\n",
        "    print(\"1. English\")\n",
        "    print(\"2. Malayalam\")\n",
        "    # Add more languages as needed\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Enter your choice (1/2): \").strip()\n",
        "        if choice == '1':\n",
        "            return 'en'  # English\n",
        "        elif choice == '2':\n",
        "            return 'ml'  # Malayalam\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter 1 or 2.\")\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    # Ask user for language choice\n",
        "    target_language = ask_language()\n",
        "\n",
        "    # Generate route description based on chosen language\n",
        "    route_description = generate_route_description(start_location, end_location, target_language)\n",
        "\n",
        "    language_name = {\n",
        "        'en': 'English',\n",
        "        'ml': 'Malayalam'\n",
        "        # Add more languages as needed\n",
        "    }.get(target_language, 'Unknown')\n",
        "\n",
        "    print(f\"Route Description (in {language_name}):\")\n",
        "    print(route_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "DjyKtNHBOIZz",
        "outputId": "e5ca9610-b189-4d2f-d46b-d42de3bbaa3d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from thrissur to kochi\n",
            "Please choose the language for the route description:\n",
            "1. English\n",
            "2. Malayalam\n",
            "Enter your choice (1/2): 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidRequestError",
          "evalue": "This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-384445fe1cf8>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Generate route description based on chosen language\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mroute_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_route_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     language_name = {\n",
            "\u001b[0;32m<ipython-input-42-384445fe1cf8>\u001b[0m in \u001b[0;36mgenerate_route_description\u001b[0;34m(start_location, end_location, target_language)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Generate response from OpenAI using AI-4 India's multilingual model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# AI-4 India's multilingual model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: This is a chat model and not supported in the v1/completions endpoint. Did you mean to use v1/chat/completions?"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvn0x6IdCbCf",
        "outputId": "b98db22a-dbfa-46f3-d9e9-e850302a705c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.6.2)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "from googletrans import Translator\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "def detect_language(text):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"gpt-3.5-turbo-instruct\",\n",
        "        prompt=f\"Detect the language of the following text:\\n\\n{text}\",\n",
        "        max_tokens=5\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def translate_to_english(text, source_language):\n",
        "    try:\n",
        "        translation = translator.translate(text, src=source_language, dest='en')\n",
        "        return translation.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error translating to English: {e}\")\n",
        "        return text\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content'].strip()\n",
        "\n",
        "def translate_description(route_description, target_language):\n",
        "    if target_language == 'en':\n",
        "        return route_description\n",
        "    else:\n",
        "        try:\n",
        "            translation = translator.translate(route_description, dest=target_language)\n",
        "            return translation.text\n",
        "        except Exception as e:\n",
        "            print(f\"Error translating description: {e}\")\n",
        "            return route_description\n",
        "\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    detected_language = detect_language(user_input)\n",
        "    if detected_language.lower() in ['hindi', 'malayalam']:\n",
        "        user_input = translate_to_english(user_input, detected_language.lower())\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    print(\"Route Description (in English):\", route_description)\n",
        "\n",
        "    target_language = input(\"Enter language code for translation (e.g., 'hi' for Hindi, 'ml' for Malayalam): \").lower()\n",
        "\n",
        "    translated_description = translate_description(route_description, target_language)\n",
        "    print(f\"Route Description (in {target_language}):\", translated_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "YS0BAlzjCgrx",
        "outputId": "8bf10d61-dd31-4ae7-c8e6-969519ba0b31"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: തൃശൂർ മുതൽ കൊച്ചി വരെ\n",
            "Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-a898ec0c6d08>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your request: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Exiting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import openai\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location, target_language='en'):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    # Generate response from OpenAI using AI-4 India's multilingual model\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-instruct\",  # AI-4 India's multilingual model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=500,  # Adjust as needed\n",
        "        stop=[\"\\n\"]\n",
        "    )\n",
        "    route_description = response.choices[0].message['content'].strip()\n",
        "\n",
        "    return route_description\n",
        "\n",
        "# Function to ask user for language choice\n",
        "def ask_language():\n",
        "    print(\"Please choose the language for the route description:\")\n",
        "    print(\"1. English\")\n",
        "    print(\"2. Malayalam\")\n",
        "    # Add more languages as needed\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Enter your choice (1/2): \").strip()\n",
        "        if choice == '1':\n",
        "            return 'en'  # English\n",
        "        elif choice == '2':\n",
        "            return 'ml'  # Malayalam\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter 1 or 2.\")\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    # Ask user for language choice\n",
        "    target_language = ask_language()\n",
        "\n",
        "    # Generate route description based on chosen language\n",
        "    route_description = generate_route_description(start_location, end_location, target_language)\n",
        "\n",
        "    language_name = {\n",
        "        'en': 'English',\n",
        "        'ml': 'Malayalam'\n",
        "        # Add more languages as needed\n",
        "    }.get(target_language, 'Unknown')\n",
        "\n",
        "    print(f\"Route Description (in {language_name}):\")\n",
        "    print(route_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "5vUhx-9qO4hr",
        "outputId": "09d7561c-828e-406c-8252-419f4bf7d51b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from kannur to kozhikode\n",
            "Please choose the language for the route description:\n",
            "1. English\n",
            "2. Malayalam\n",
            "Enter your choice (1/2): 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidRequestError",
          "evalue": "This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-fb8f9686113d>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Generate route description based on chosen language\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mroute_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_route_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     language_name = {\n",
            "\u001b[0;32m<ipython-input-44-fb8f9686113d>\u001b[0m in \u001b[0;36mgenerate_route_description\u001b[0;34m(start_location, end_location, target_language)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Generate response from OpenAI using AI-4 India's multilingual model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo-instruct\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# AI-4 India's multilingual model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key if needed)\n",
        "os.environ[\"OPENAI_API_KEY\"] =\n",
        "# Function to extract locations from user input\n",
        "def extract_locations(user_input):\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "# Function to generate route description using Indic-BERT\n",
        "def generate_route_description(start_location, end_location, target_language='en'):\n",
        "    # Initialize tokenizer and model for Indic-BERT\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indic-bert\")\n",
        "\n",
        "    # Prepare inputs and encode them\n",
        "    inputs = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "    input_ids = tokenizer.encode(inputs, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    # Generate response from Indic-BERT\n",
        "    translated_texts = pipeline(\n",
        "        \"translation_xx_to_yy\",  # Replace with the appropriate translation model\n",
        "        model=model,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "    route_description = translated_texts(inputs, target_lang=target_language)[0]['translation_text']\n",
        "\n",
        "    return route_description\n",
        "\n",
        "# Function to ask user for language choice\n",
        "def ask_language():\n",
        "    print(\"Please choose the language for the route description:\")\n",
        "    print(\"1. English\")\n",
        "    print(\"2. Malayalam\")\n",
        "    # Add more languages as needed\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Enter your choice (1/2): \").strip()\n",
        "        if choice == '1':\n",
        "            return 'en'  # English\n",
        "        elif choice == '2':\n",
        "            return 'ml'  # Malayalam\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter 1 or 2.\")\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    # Ask user for language choice\n",
        "    target_language = ask_language()\n",
        "\n",
        "    # Generate route description based on chosen language using Indic-BERT\n",
        "    route_description = generate_route_description(start_location, end_location, target_language)\n",
        "\n",
        "    language_name = {\n",
        "        'en': 'English',\n",
        "        'ml': 'Malayalam'\n",
        "        # Add more languages as needed\n",
        "    }.get(target_language, 'Unknown')\n",
        "\n",
        "    print(f\"Route Description (in {language_name}):\")\n",
        "    print(route_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701,
          "referenced_widgets": [
            "7b3b42d59f7d4b8aa2471cfac519e21a",
            "d3cab7d059fa4267a734fc2083b971ac",
            "78c5eb51376c46ea8178e7df8cf58071",
            "cc8d6e614c024b39aedf8759f7afe2ad",
            "2ee707a5073d4f1e912d55cb062b0e50",
            "2c2fdad6928b4d86aa62b05125bd4240",
            "c0737f7b928949e08e8f423581609ac6",
            "476aa9e8c565458f95762be1ca37a91b",
            "f99236a494494925b1d2db678bd1d887",
            "a72020cbee4e44a394887110d9fcbf3f",
            "bc47420103eb4f74949f0649a302a766",
            "0c9fae0be16b4e158e985f44dfbe3392",
            "3af4ac24a945497d81f4123be9682902",
            "6f0c3219efa3448ba9df9cdc4f964edb",
            "d2a949a810634c4aafebf649bad2c98a",
            "c2534b1d31934f6a993e0c34cb982e7a",
            "a4e0484a25f749e281b5e3d0ade32379",
            "95955fdee2434bd3a616bfcf46ea8b0e",
            "02a0fa17bbd74da8a9953d0f0eea0ea6",
            "9cb745bce5db45898618e3f6d0622204",
            "c828d8b92637480f8ff2a1c07151e59e",
            "4d27e75a0e40458fa1ca9d8441f53a0b"
          ]
        },
        "id": "0jqY3EgPOrGL",
        "outputId": "176c8928-933e-4d55-811c-207057b7b440"
      },
      "execution_count": 45,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from kannur to kozhikode\n",
            "Please choose the language for the route description:\n",
            "1. English\n",
            "2. Malayalam\n",
            "Enter your choice (1/2): 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/507 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b3b42d59f7d4b8aa2471cfac519e21a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/5.65M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c9fae0be16b4e158e985f44dfbe3392"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized configuration class <class 'transformers.models.albert.configuration_albert.AlbertConfig'> for this kind of AutoModel: AutoModelForSeq2SeqLM.\nModel type should be one of BartConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, EncoderDecoderConfig, FSMTConfig, GPTSanJapaneseConfig, LEDConfig, LongT5Config, M2M100Config, MarianConfig, MBartConfig, MT5Config, MvpConfig, NllbMoeConfig, PegasusConfig, PegasusXConfig, PLBartConfig, ProphetNetConfig, SeamlessM4TConfig, SeamlessM4Tv2Config, SwitchTransformersConfig, T5Config, UMT5Config, XLMProphetNetConfig.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-5df9c3baf24c>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Generate route description based on chosen language using Indic-BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mroute_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_route_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     language_name = {\n",
            "\u001b[0;32m<ipython-input-45-5df9c3baf24c>\u001b[0m in \u001b[0;36mgenerate_route_description\u001b[0;34m(start_location, end_location, target_language)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Initialize tokenizer and model for Indic-BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ai4bharat/indic-bert\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ai4bharat/indic-bert\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Prepare inputs and encode them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             )\n\u001b[0;32m--> 566\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;34mf\"Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.albert.configuration_albert.AlbertConfig'> for this kind of AutoModel: AutoModelForSeq2SeqLM.\nModel type should be one of BartConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, EncoderDecoderConfig, FSMTConfig, GPTSanJapaneseConfig, LEDConfig, LongT5Config, M2M100Config, MarianConfig, MBartConfig, MT5Config, MvpConfig, NllbMoeConfig, PegasusConfig, PegasusXConfig, PLBartConfig, ProphetNetConfig, SeamlessM4TConfig, SeamlessM4Tv2Config, SwitchTransformersConfig, T5Config, UMT5Config, XLMProphetNetConfig."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key if needed)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "# Function to extract locations from user input\n",
        "def extract_locations(user_input):\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "# Function to generate route description using Indic-BERT\n",
        "def generate_route_description(start_location, end_location, target_language='en'):\n",
        "    # Initialize tokenizer and model for Indic-BERT\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/indic-bert\")\n",
        "\n",
        "    # Prepare inputs and encode them\n",
        "    inputs = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "    input_ids = tokenizer.encode(inputs, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    # Generate response from Indic-BERT\n",
        "    translated_texts = pipeline(\n",
        "        \"translation_xx_to_yy\",  # Replace with the appropriate translation model\n",
        "        model=model,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "    route_description = translated_texts(inputs, target_lang=target_language)[0]['translation_text']\n",
        "\n",
        "    return route_description\n",
        "\n",
        "# Function to ask user for language choice\n",
        "def ask_language():\n",
        "    print(\"Please choose the language for the route description:\")\n",
        "    print(\"1. English\")\n",
        "    print(\"2. Malayalam\")\n",
        "    # Add more languages as needed\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Enter your choice (1/2): \").strip()\n",
        "        if choice == '1':\n",
        "            return 'en'  # English\n",
        "        elif choice == '2':\n",
        "            return 'ml'  # Malayalam\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter 1 or 2.\")\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    # Ask user for language choice\n",
        "    target_language = ask_language()\n",
        "\n",
        "    # Generate route description based on chosen language using Indic-BERT\n",
        "    route_description = generate_route_description(start_location, end_location, target_language)\n",
        "\n",
        "    language_name = {\n",
        "        'en': 'English',\n",
        "        'ml': 'Malayalam'\n",
        "        # Add more languages as needed\n",
        "    }.get(target_language, 'Unknown')\n",
        "\n",
        "    print(f\"Route Description (in {language_name}):\")\n",
        "    print(route_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "r_Sg_Q5PPxZY",
        "outputId": "88df3222-df6e-4901-aa4c-14b709ec4ddf"
      },
      "execution_count": 47,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: from kannur to kozhikode\n",
            "Please choose the language for the route description:\n",
            "1. English\n",
            "2. Malayalam\n",
            "Enter your choice (1/2): 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized configuration class <class 'transformers.models.albert.configuration_albert.AlbertConfig'> for this kind of AutoModel: AutoModelForSeq2SeqLM.\nModel type should be one of BartConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, EncoderDecoderConfig, FSMTConfig, GPTSanJapaneseConfig, LEDConfig, LongT5Config, M2M100Config, MarianConfig, MBartConfig, MT5Config, MvpConfig, NllbMoeConfig, PegasusConfig, PegasusXConfig, PLBartConfig, ProphetNetConfig, SeamlessM4TConfig, SeamlessM4Tv2Config, SwitchTransformersConfig, T5Config, UMT5Config, XLMProphetNetConfig.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-5df9c3baf24c>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# Generate route description based on chosen language using Indic-BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mroute_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_route_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     language_name = {\n",
            "\u001b[0;32m<ipython-input-47-5df9c3baf24c>\u001b[0m in \u001b[0;36mgenerate_route_description\u001b[0;34m(start_location, end_location, target_language)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Initialize tokenizer and model for Indic-BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ai4bharat/indic-bert\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ai4bharat/indic-bert\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Prepare inputs and encode them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             )\n\u001b[0;32m--> 566\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;34mf\"Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.albert.configuration_albert.AlbertConfig'> for this kind of AutoModel: AutoModelForSeq2SeqLM.\nModel type should be one of BartConfig, BigBirdPegasusConfig, BlenderbotConfig, BlenderbotSmallConfig, EncoderDecoderConfig, FSMTConfig, GPTSanJapaneseConfig, LEDConfig, LongT5Config, M2M100Config, MarianConfig, MBartConfig, MT5Config, MvpConfig, NllbMoeConfig, PegasusConfig, PegasusXConfig, PLBartConfig, ProphetNetConfig, SeamlessM4TConfig, SeamlessM4Tv2Config, SwitchTransformersConfig, T5Config, UMT5Config, XLMProphetNetConfig."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from translate import Translator\n",
        "\n",
        "# Set the Hugging Face model and tokenizer for multilingual support\n",
        "model_name = \"microsoft/xtremedistil-multilingual-17\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location, target_language='en'):\n",
        "    # Prompt for the model\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    # Tokenize prompt\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(inputs.input_ids, max_length=150)\n",
        "\n",
        "    # Decode response\n",
        "    route_description = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Translate the route description to the target language\n",
        "    translator = Translator(to_lang=target_language)\n",
        "    translated_description = translator.translate(route_description)\n",
        "\n",
        "    return translated_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "        continue\n",
        "\n",
        "    # Example: Translating to Spanish ('es'). You can change 'es' to any other language code as needed.\n",
        "    route_description = generate_route_description(start_location, end_location, target_language='es')\n",
        "    print(\"Route Description (in Spanish):\", route_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "N3NcA1CLKtT5",
        "outputId": "c90c872a-6eea-43b5-bc0b-119782cc4410"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "microsoft/xtremedistil-multilingual-17 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/microsoft/xtremedistil-multilingual-17/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    400\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1222\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m         \u001b[0;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hf_file_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhttp_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1646\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    373\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-6673c144-4cc154101a511c427e710618;29bb9b27-0048-4f4e-957d-f452ff4eb9c7)\n\nRepository Not Found for url: https://huggingface.co/microsoft/xtremedistil-multilingual-17/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f1ffe18e0e3e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Set the Hugging Face model and tokenizer for multilingual support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"microsoft/xtremedistil-multilingual-17\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    485\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         ) from e\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: microsoft/xtremedistil-multilingual-17 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "  # Regular expressions to extract locations (adapt for other languages)\n",
        "  patterns = [\n",
        "      re.compile(r\"(?:take me from|from|I want to go from)\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "  ]\n",
        "\n",
        "  for pattern in patterns:\n",
        "    match = pattern.search(user_input)\n",
        "    if match:\n",
        "      start_location = match.group(1).strip()\n",
        "      end_location = match.group(2).strip()\n",
        "      return start_location, end_location\n",
        "  return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location, language=\"en\"):\n",
        "  # Prompt for the OpenAI API with language parameter\n",
        "  prompt = f\"Provide a detailed driving route from {start_location} to {end_location} in {language}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "          {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  return response.choices[0].message.content.strip()\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "  user_input = input(\"Enter your request: \")\n",
        "  if user_input.lower() == 'exit':\n",
        "    print('Exiting')\n",
        "    break\n",
        "\n",
        "  start_location, end_location = extract_locations(user_input)\n",
        "  if not start_location or not end_location:\n",
        "    print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "    continue\n",
        "\n",
        "  # Get user language preference\n",
        "  language = input(\"Choose your preferred language (en for English, otherwise specify): \")\n",
        "\n",
        "  route_description = generate_route_description(start_location, end_location, language)\n",
        "  print(\"Route Description:\", route_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59k_MF6fIt3k",
        "outputId": "a0ece839-769e-4e9a-cb05-1c069df4e76c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\n",
            "Enter your request: take me from kannur to kozhikode\n",
            "Choose your preferred language (en for English, otherwise specify): hi\n",
            "Route Description: Sure! Here is a detailed driving route from Kannur to Kozhikode:\n",
            "\n",
            "1. Start from Kannur and head south on NH 66 (also known as Kannur - Kozhikode Road).\n",
            "2. Continue on NH 66 for about 49 km.\n",
            "3. You will pass through places like Thalassery and Mahe along the way.\n",
            "4. After approximately 49 km, you will reach Kozhikode district.\n",
            "5. Stay on NH 66 which becomes Mavoor Road as you approach Kozhikode city.\n",
            "6. Once you enter Kozhikode city, continue straight on Mavoor Road.\n",
            "7. Drive for about 8 km on Mavoor Road until you reach the heart of Kozhikode city.\n",
            "8. Look out for major landmarks such as Mananchira Square, Sarovaram Biopark, and Kozhikode Beach as you navigate the city streets.\n",
            "9. Finally, reach your destination in Kozhikode.\n",
            "\n",
            "Distance: The total distance between Kannur and Kozhikode is approximately 90 km, and the driving time is around 2 to 3 hours depending on traffic conditions.\n",
            "\n",
            "Please note, road conditions and traffic patterns may vary, so make sure to use GPS or maps for real-time updates during your journey.\n",
            "Enter your request: xit\n",
            "Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\n",
            "Enter your request: exit\n",
            "Exiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import pipeline\n",
        "import openai\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Set your OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Load translation model, specifying source and target languages\n",
        "translator = pipeline(\"translation_en_to_hi\", engine=\"openai\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def extract_locations(user_input):\n",
        "  # Regular expressions to extract locations (adapt for other languages)\n",
        "  patterns = [\n",
        "      re.compile(r\"(?:take me from|from|I want to go from)\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "  ]\n",
        "\n",
        "  for pattern in patterns:\n",
        "    match = pattern.search(user_input)\n",
        "    if match:\n",
        "      start_location = match.group(1).strip()\n",
        "      end_location = match.group(2).strip()\n",
        "      return start_location, end_location\n",
        "  return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location, language=\"en\"):\n",
        "  # Use an open-source LLM like BLOOM for route generation in English\n",
        "  # Install required libraries: transformers huggingface-hub\n",
        "  # pip install transformers huggingface-hub\n",
        "  model_name = \"bigscience/bloom\"  # Replace with your chosen model\n",
        "  tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
        "  model = transformers.AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "  # Prompt for route generation (ensure compatibility with your LLM)\n",
        "  prompt = f\"Provide a detailed driving route from {start_location} to {end_location} in English. Include major turns, landmarks, and distances.\"\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "  # Generate route description\n",
        "  output = model.generate(**input_ids)\n",
        "  route_description = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
        "\n",
        "  # Translate the route description to the desired language (if not English)\n",
        "  if language != \"en\":\n",
        "    translated_route_description = translator(route_description, source_language=\"en\", target_language=language)[0][\"translation_text\"]\n",
        "    return translated_route_description\n",
        "  else:\n",
        "    return route_description\n",
        "\n",
        "# Run the chatbot in a loop\n",
        "print(\"Greetings! I am SARATHI, developed by NIT Calicut students. Type 'exit' to quit.\")\n",
        "while True:\n",
        "  user_input = input(\"Enter your request: \")\n",
        "  if user_input.lower() == 'exit':\n",
        "    print('Exiting')\n",
        "    break\n",
        "\n",
        "  start_location, end_location = extract_locations(user_input)\n",
        "  if not start_location or not end_location:\n",
        "    print(\"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "    continue\n",
        "\n",
        "  # Get user language preference\n",
        "  language = input(\"Choose your preferred language (en for English, otherwise specify): \")\n",
        "\n",
        "  route_description = generate_route_description(start_location, end_location, language)\n",
        "  print(\"Route Description:\", route_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "WijyZxBQI8wS",
        "outputId": "decc835d-6c3f-44d3-d0e6-55cfbddcfae7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The task does not provide any default models for options ('en', 'hi')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-34fcc6220db9>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load translation model, specifying source and target languages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"translation_en_to_hi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"openai\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;31m# At that point framework might still be undetermined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_model_and_revision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargeted_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m         \u001b[0mrevision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevision\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrevision\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdefault_revision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         logger.warning(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mget_default_model_and_revision\u001b[0;34m(targeted_task, framework, task_options)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask_options\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The task does not provide any default models for options {task_options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mdefault_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_options\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m\"model\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The task does not provide any default models for options ('en', 'hi')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install huggingface-hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9mxtZ8JJN8J",
        "outputId": "bbf64861-8bcd-4e63-e695-d53ebc8e2afd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.23.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIVkt0D25y4q",
        "outputId": "286d3ecc-a0d9-49f6-a553-12e8db114916"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.0.1 (from gradio)\n",
            "  Downloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.2-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=ec8d27ee9a01787a52c0d79c179f63029bec75f2ae0cc21cbc0de0357bec99ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: ffmpy, websockets, uvloop, ujson, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.9.0\n",
            "    Uninstalling h11-0.9.0:\n",
            "      Successfully uninstalled h11-0.9.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 0.9.1\n",
            "    Uninstalling httpcore-0.9.1:\n",
            "      Successfully uninstalled httpcore-0.9.1\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.13.3\n",
            "    Uninstalling httpx-0.13.3:\n",
            "      Successfully uninstalled httpx-0.13.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "googletrans 3.0.0 requires httpx==0.13.3, but you have httpx 0.27.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.2 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.36.1 gradio-client-1.0.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.5 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.9 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "import gradio as gr\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def get_route_description(user_input):\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        return \"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    return f\"Route Description: {route_description}\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=get_route_description,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"SARATHI Route Description Chatbot\",\n",
        "    description=\"Greetings! I am SARATHI, developed by NIT Calicut students. Enter a request like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V42_6evk6DF8",
        "outputId": "19f87b45-b9c3-4461-858c-0888d88211d5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: You are using gradio version 3.1.4, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Failed to connect to ec2.gradio.app:22: [Errno 110] Connection timed out\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\", line 74, in create_tunnel\n",
            "    client.connect(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/paramiko/client.py\", line 386, in connect\n",
            "    sock.connect(addr)\n",
            "TimeoutError: [Errno 110] Connection timed out\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-18-d72743313916>\", line 56, in <cell line: 56>\n",
            "    iface.launch(debug=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 895, in launch\n",
            "    share_url = networking.setup_tunnel(self.server_port, None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 176, in setup_tunnel\n",
            "    return create_tunnel(payload, LOCALHOST_NAME, local_server_port)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\", line 82, in create_tunnel\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\u001b[0m in \u001b[0;36mcreate_tunnel\u001b[0;34m(payload, local_server, local_server_port)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             client.connect(\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mhostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"host\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paramiko/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, hostname, port, username, password, pkey, key_filename, timeout, allow_agent, look_for_keys, compress, sock, gss_auth, gss_kex, gss_deleg_creds, gss_host, banner_timeout, auth_timeout, channel_timeout, gss_trust_dns, passphrase, disabled_algorithms, transport_factory, auth_strategy)\u001b[0m\n\u001b[1;32m    385\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                     \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# Break out of the loop on success\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-d72743313916>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, quiet, _frontend)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                     \u001b[0mshare_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetworking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshare_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/networking.py\u001b[0m in \u001b[0;36msetup_tunnel\u001b[0;34m(local_server_port, endpoint)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCALHOST_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_server_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\u001b[0m in \u001b[0;36mcreate_tunnel\u001b[0;34m(payload, local_server, local_server_port)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'*** Failed to connect to {payload[\"host\"]}:{payload[\"port\"]}: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "import gradio as gr\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def get_route_description(user_input):\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        return \"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    return f\"Route Description: {route_description}\"\n",
        "\n",
        "# Define Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_route_description,\n",
        "    inputs=gr.inputs.Textbox(label=\"Enter your request:\"),\n",
        "    outputs=gr.outputs.Textbox(label=\"Route Description\"),\n",
        "    title=\"SARATHI Route Description Chatbot\",\n",
        "    description=\"Greetings! I am SARATHI, developed by NIT Calicut students. Enter a request like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        ")\n",
        "\n",
        "# Launch Gradio app in Colab\n",
        "iface.launch(debug=True,share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mSk0TQTYGBDd",
        "outputId": "63a2956d-53b7-4784-c3c6-d6e01d42f739"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/outputs.py:21: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: You are using gradio version 3.1.4, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Failed to connect to ec2.gradio.app:22: [Errno 110] Connection timed out\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\", line 74, in create_tunnel\n",
            "    client.connect(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/paramiko/client.py\", line 386, in connect\n",
            "    sock.connect(addr)\n",
            "TimeoutError: [Errno 110] Connection timed out\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-21-3f29a7d58ba9>\", line 58, in <cell line: 58>\n",
            "    iface.launch(debug=True,share=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 895, in launch\n",
            "    share_url = networking.setup_tunnel(self.server_port, None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 176, in setup_tunnel\n",
            "    return create_tunnel(payload, LOCALHOST_NAME, local_server_port)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\", line 82, in create_tunnel\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\u001b[0m in \u001b[0;36mcreate_tunnel\u001b[0;34m(payload, local_server, local_server_port)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             client.connect(\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mhostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"host\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paramiko/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, hostname, port, username, password, pkey, key_filename, timeout, allow_agent, look_for_keys, compress, sock, gss_auth, gss_kex, gss_deleg_creds, gss_host, banner_timeout, auth_timeout, channel_timeout, gss_trust_dns, passphrase, disabled_algorithms, transport_factory, auth_strategy)\u001b[0m\n\u001b[1;32m    385\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                     \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# Break out of the loop on success\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-3f29a7d58ba9>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Launch Gradio app in Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, quiet, _frontend)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                     \u001b[0mshare_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetworking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshare_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/networking.py\u001b[0m in \u001b[0;36msetup_tunnel\u001b[0;34m(local_server_port, endpoint)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCALHOST_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_server_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\u001b[0m in \u001b[0;36mcreate_tunnel\u001b[0;34m(payload, local_server, local_server_port)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'*** Failed to connect to {payload[\"host\"]}:{payload[\"port\"]}: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "import gradio as gr\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def get_route_description(user_input):\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        return \"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    return f\"Route Description: {route_description}\"\n",
        "\n",
        "# Define Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_route_description,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"SARATHI Route Description Chatbot\",\n",
        "    description=\"Greetings! I am SARATHI, developed by NIT Calicut students. Enter a request like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        ")\n",
        "\n",
        "# Launch Gradio interface in Colab\n",
        "iface.launch(inline=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S0SHpN8k-Uza",
        "outputId": "9ca3deb2-7803-457b-877c-833f7274175a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: You are using gradio version 3.1.4, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Failed to connect to ec2.gradio.app:22: [Errno 110] Connection timed out\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\", line 74, in create_tunnel\n",
            "    client.connect(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/paramiko/client.py\", line 386, in connect\n",
            "    sock.connect(addr)\n",
            "TimeoutError: [Errno 110] Connection timed out\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-6-60c141473cb0>\", line 58, in <cell line: 58>\n",
            "    iface.launch(inline=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 895, in launch\n",
            "    share_url = networking.setup_tunnel(self.server_port, None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 176, in setup_tunnel\n",
            "    return create_tunnel(payload, LOCALHOST_NAME, local_server_port)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\", line 82, in create_tunnel\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\u001b[0m in \u001b[0;36mcreate_tunnel\u001b[0;34m(payload, local_server, local_server_port)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             client.connect(\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mhostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"host\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paramiko/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, hostname, port, username, password, pkey, key_filename, timeout, allow_agent, look_for_keys, compress, sock, gss_auth, gss_kex, gss_deleg_creds, gss_host, banner_timeout, auth_timeout, channel_timeout, gss_trust_dns, passphrase, disabled_algorithms, transport_factory, auth_strategy)\u001b[0m\n\u001b[1;32m    385\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                     \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# Break out of the loop on success\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-60c141473cb0>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Launch Gradio interface in Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, quiet, _frontend)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                     \u001b[0mshare_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetworking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshare_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/networking.py\u001b[0m in \u001b[0;36msetup_tunnel\u001b[0;34m(local_server_port, endpoint)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCALHOST_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_server_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\u001b[0m in \u001b[0;36mcreate_tunnel\u001b[0;34m(payload, local_server, local_server_port)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'*** Failed to connect to {payload[\"host\"]}:{payload[\"port\"]}: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "import streamlit as st\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def get_route_description(user_input):\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        return \"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    return f\"Route Description: {route_description}\"\n",
        "\n",
        "# Streamlit web app\n",
        "def main():\n",
        "    st.title(\"SARATHI Route Description Chatbot\")\n",
        "    st.markdown(\"Greetings! I am SARATHI, developed by NIT Calicut students. Enter a request like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "\n",
        "    user_input = st.text_input(\"Enter your request:\")\n",
        "    if user_input:\n",
        "        route_description = get_route_description(user_input)\n",
        "        st.text(route_description)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "WooHdxsn-8zk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "import streamlit as st\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def get_route_description(user_input):\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        return \"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    return f\"Route Description: {route_description}\"\n",
        "\n",
        "# Streamlit web app\n",
        "def main():\n",
        "    st.title(\"SARATHI Route Description Chatbot\")\n",
        "    st.markdown(\"Greetings! I am SARATHI, developed by NIT Calicut students. Enter a request like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "\n",
        "    user_input = st.text_input(\"Enter your request:\")\n",
        "    if user_input:\n",
        "        route_description = get_route_description(user_input)\n",
        "        st.text(route_description)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Bzzr8xhu_Yj_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-kqRWDq-99_",
        "outputId": "374321e0-6af5-479e-d0d5-4507c4e29524"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.35.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import streamlit as st\n",
        "import os\n",
        "import openai\n",
        "import re\n",
        "import streamlit as st\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def get_route_description(user_input):\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        return \"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    return f\"Route Description: {route_description}\"\n",
        "\n",
        "# Streamlit web app\n",
        "def main():\n",
        "    st.title(\"SARATHI Route Description Chatbot\")\n",
        "    st.markdown(\"Greetings! I am SARATHI, developed by NIT Calicut students. Enter a request like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "\n",
        "    user_input = st.text_input(\"Enter your request:\")\n",
        "    if user_input:\n",
        "        route_description = get_route_description(user_input)\n",
        "        st.text(route_description)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(port='8501')\n",
        "print('Streamlit app can be accessed at:', public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "uAfxUrLj_rw8",
        "outputId": "c58b54da-470f-4a07-f0c3-c6ae9b6cbd1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2024-06-20T04:54:45+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2024-06-20T04:54:45+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-4806d7ebfc61>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'8501'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Streamlit app can be accessed at:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    399\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.set_auth_token('')\n"
      ],
      "metadata": {
        "id": "7kkM4hiMASfs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def get_route_description(user_input):\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        return \"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    return f\"Route Description: {route_description}\"\n",
        "\n",
        "# Streamlit web app\n",
        "def main():\n",
        "    st.title(\"SARATHI Route Description Chatbot\")\n",
        "    st.markdown(\"Greetings! I am SARATHI, developed by NIT Calicut students. Enter a request like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\")\n",
        "\n",
        "    user_input = st.text_input(\"Enter your request:\")\n",
        "    if user_input:\n",
        "        route_description = get_route_description(user_input)\n",
        "        st.text(route_description)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set ngrok auth token\n",
        "    ngrok.set_auth_token('your_ngrok_authtoken')\n",
        "\n",
        "    # Launch Streamlit app with ngrok\n",
        "    public_url = ngrok.connect(port='8501')\n",
        "    print('Streamlit app can be accessed at:', public_url)\n",
        "\n",
        "    # Prevent the script from terminating while using ngrok\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "Sn_zN6kfAZRw",
        "outputId": "8a8f4c57-2c77-4190-b949-cd23d1a74ac8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2024-06-20T04:59:29+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: The authtoken you specified is an ngrok v1 authtoken, but you're using ngrok v2.\\nYour authtoken: your_ngrok_authtoken\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_106\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2024-06-20T04:59:29+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: The authtoken you specified is an ngrok v1 authtoken, but you're using ngrok v2.\\nYour authtoken: your_ngrok_authtoken\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_106\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2024-06-20T04:59:29+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: The authtoken you specified is an ngrok v1 authtoken, but you're using ngrok v2.\\nYour authtoken: your_ngrok_authtoken\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_106\\r\\n\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-06-20T04:59:29+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context canceled\"\n",
            "CRITICAL:pyngrok.process.ngrok:t=2024-06-20T04:59:29+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: The authtoken you specified is an ngrok v1 authtoken, but you're using ngrok v2.\\nYour authtoken: your_ngrok_authtoken\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_106\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: The authtoken you specified is an ngrok v1 authtoken, but you're using ngrok v2.\\nYour authtoken: your_ngrok_authtoken\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_106\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-80e1247fa3b7>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Launch Streamlit app with ngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'8501'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Streamlit app can be accessed at:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    399\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: The authtoken you specified is an ngrok v1 authtoken, but you're using ngrok v2.\\nYour authtoken: your_ngrok_authtoken\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_106\\r\\n."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "import gradio as gr\n",
        "\n",
        "# Set the OpenAI API key (replace with your actual key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def extract_locations(user_input):\n",
        "    # Regular expressions to extract locations from input\n",
        "    patterns = [\n",
        "        re.compile(r\"take me from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE),\n",
        "        re.compile(r\"i want to go from\\s+(.+?)\\s+to\\s+(.+)\", re.IGNORECASE)\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = pattern.search(user_input)\n",
        "        if match:\n",
        "            start_location = match.group(1).strip()\n",
        "            end_location = match.group(2).strip()\n",
        "            return start_location, end_location\n",
        "    return None, None\n",
        "\n",
        "def generate_route_description(start_location, end_location):\n",
        "    # Prompt for the OpenAI API\n",
        "    prompt = f\"Provide a detailed driving route from {start_location} to {end_location}. Include major turns, landmarks, and distances.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def get_route_description(user_input):\n",
        "    start_location, end_location = extract_locations(user_input)\n",
        "    if not start_location or not end_location:\n",
        "        return \"Invalid input format. Please use phrases like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        "\n",
        "    route_description = generate_route_description(start_location, end_location)\n",
        "    return f\"Route Description: {route_description}\"\n",
        "\n",
        "# Define Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_route_description,\n",
        "    inputs=gr.inputs.Textbox(label=\"Enter your request:\"),\n",
        "    outputs=gr.outputs.Textbox(label=\"Route Description\"),\n",
        "    title=\"SARATHI Route Description Chatbot\",\n",
        "    description=\"Greetings! I am SARATHI, developed by NIT Calicut students. Enter a request like 'take me from [start location] to [end location]', 'from [start location] to [end location]', or 'I want to go from [start location] to [end location]'.\"\n",
        ")\n",
        "\n",
        "# Launch Gradio app\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HrRfY_y2BWNO",
        "outputId": "38582690-cfd3-49ad-a11b-81156c62bcc7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/outputs.py:21: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: You are using gradio version 3.1.4, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Failed to connect to ec2.gradio.app:22: [Errno 110] Connection timed out\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\", line 74, in create_tunnel\n",
            "    client.connect(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/paramiko/client.py\", line 386, in connect\n",
            "    sock.connect(addr)\n",
            "TimeoutError: [Errno 110] Connection timed out\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-17-acee51e84d91>\", line 58, in <cell line: 58>\n",
            "    iface.launch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 895, in launch\n",
            "    share_url = networking.setup_tunnel(self.server_port, None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 176, in setup_tunnel\n",
            "    return create_tunnel(payload, LOCALHOST_NAME, local_server_port)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\", line 82, in create_tunnel\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\u001b[0m in \u001b[0;36mcreate_tunnel\u001b[0;34m(payload, local_server, local_server_port)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             client.connect(\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0mhostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"host\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/paramiko/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, hostname, port, username, password, pkey, key_filename, timeout, allow_agent, look_for_keys, compress, sock, gss_auth, gss_kex, gss_deleg_creds, gss_host, banner_timeout, auth_timeout, channel_timeout, gss_trust_dns, passphrase, disabled_algorithms, transport_factory, auth_strategy)\u001b[0m\n\u001b[1;32m    385\u001b[0m                             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                     \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                     \u001b[0;31m# Break out of the loop on success\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-acee51e84d91>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Launch Gradio app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0miface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, quiet, _frontend)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                     \u001b[0mshare_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetworking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshare_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshare_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/networking.py\u001b[0m in \u001b[0;36msetup_tunnel\u001b[0;34m(local_server_port, endpoint)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_tunnel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCALHOST_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_server_port\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/tunneling.py\u001b[0m in \u001b[0;36mcreate_tunnel\u001b[0;34m(payload, local_server, local_server_port)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'*** Failed to connect to {payload[\"host\"]}:{payload[\"port\"]}: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio==3.1.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHbwQk9d6UM6",
        "outputId": "3503caee-1a14-4233-f471-afc292dc070d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio==3.1.4 in /usr/local/lib/python3.10/dist-packages (3.1.4)\n",
            "Requirement already satisfied: analytics-python in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (1.4.post1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (3.9.5)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (0.12.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (0.3.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (3.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (1.25.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (3.10.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (2.0.3)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (3.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (9.4.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (3.20.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (0.0.9)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (0.25.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (2.31.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (0.30.1)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (0.25.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio==3.1.4) (2.7.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.1.4) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.1.4) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.1.4) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.1.4) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.1.4) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.1.4) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from analytics-python->gradio==3.1.4) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from analytics-python->gradio==3.1.4) (1.6)\n",
            "Requirement already satisfied: backoff==1.10.0 in /usr/local/lib/python3.10/dist-packages (from analytics-python->gradio==3.1.4) (1.10.0)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from analytics-python->gradio==3.1.4) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gradio==3.1.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gradio==3.1.4) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio==3.1.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gradio==3.1.4) (2024.6.2)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.1.4) (0.37.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.1.4) (4.12.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.1.4) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.1.4) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.1.4) (2.1.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.1.4) (3.7.1)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.1.4) (0.15.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.1.4) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->gradio==3.1.4) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->gradio==3.1.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->gradio==3.1.4) (2.18.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.1.4) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.1.4) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.1.4) (0.4.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.1.4) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.1.4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.1.4) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.1.4) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.1.4) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.1.4) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.1.4) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.1.4) (2024.1)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.10/dist-packages (from paramiko->gradio==3.1.4) (4.1.3)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko->gradio==3.1.4) (42.0.8)\n",
            "Requirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.10/dist-packages (from paramiko->gradio==3.1.4) (1.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.1.4) (8.1.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko->gradio==3.1.4) (1.16.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio==3.1.4) (2.6.1)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi->gradio==3.1.4) (0.12.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]->gradio==3.1.4) (1.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.1.4) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.1.4) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.1.4) (1.0.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.1.4) (6.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.1.4) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.1.4) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio==3.1.4) (11.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko->gradio==3.1.4) (2.22)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.1.4) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.1.4) (13.7.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.1.4) (2.16.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "!pip install googletrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cGGLUT2uKi6",
        "outputId": "4f9615eb-ddfc-4b1c-9e8d-a2fc99dd0f92"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Collecting httpx==0.13.3 (from googletrans)\n",
            "  Using cached httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.6.2)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans)\n",
            "  Using cached httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans)\n",
            "  Using cached h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
            "Installing collected packages: h11, httpcore, httpx\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.12.0\n",
            "    Uninstalling h11-0.12.0:\n",
            "      Successfully uninstalled h11-0.12.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 0.15.0\n",
            "    Uninstalling httpcore-0.15.0:\n",
            "      Successfully uninstalled httpcore-0.15.0\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.25.1\n",
            "    Uninstalling httpx-0.25.1:\n",
            "      Successfully uninstalled httpx-0.25.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastapi 0.111.0 requires httpx>=0.23.0, but you have httpx 0.13.3 which is incompatible.\n",
            "gradio 3.1.4 requires h11<0.13,>=0.11, but you have h11 0.9.0 which is incompatible.\n",
            "gradio-client 1.0.1 requires httpx>=0.24.1, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.9.0 httpcore-0.9.1 httpx-0.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKaQJyXZuZFZ",
        "outputId": "74ffea44-c99d-4f45-c761-a951fdaa9736"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/cleaned_first_100_issues.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwIz3AOHuiGu",
        "outputId": "09b632ed-199b-4b78-e801-f5e8efd6f4c5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        title  \\\n",
            "0  Added python code example for parking lot    \n",
            "1                            Optimised Images   \n",
            "2                         de: Add translation   \n",
            "3                               small changes   \n",
            "4                 ru: Add Russian translation   \n",
            "\n",
            "                                              labels  \\\n",
            "0  [{\"name:\": \"needs-review\", \"description:\": \"no...   \n",
            "1  [{\"name:\": \"needs-review\", \"description:\": \"no...   \n",
            "2  [{\"name:\": \"needs-review\", \"description:\": \"no...   \n",
            "3  [{\"name:\": \"needs-review\", \"description:\": \"no...   \n",
            "4  [{\"name:\": \"needs-review\", \"description:\": \"no...   \n",
            "\n",
            "                                                body  \\\n",
            "0  …sign\\n\\n## Review the Contributing Guidelines...   \n",
            "1  ## Review the Contributing Guidelines\\n\\nBefor...   \n",
            "2  ## Review the Contributing Guidelines\\n\\nBefor...   \n",
            "3  ## Review the Contributing Guidelines\\n\\nBefor...   \n",
            "4  * Added README-ru.md\\n* Kept content of origin...   \n",
            "\n",
            "                                           issue_url  \\\n",
            "0  https://api.github.com/repos/donnemartin/syste...   \n",
            "1  https://api.github.com/repos/donnemartin/syste...   \n",
            "2  https://api.github.com/repos/donnemartin/syste...   \n",
            "3  https://api.github.com/repos/donnemartin/syste...   \n",
            "4  https://api.github.com/repos/donnemartin/syste...   \n",
            "\n",
            "                                      repository_url language  \n",
            "0  https://api.github.com/repos/donnemartin/syste...       en  \n",
            "1  https://api.github.com/repos/donnemartin/syste...       en  \n",
            "2  https://api.github.com/repos/donnemartin/syste...       en  \n",
            "3  https://api.github.com/repos/donnemartin/syste...       en  \n",
            "4  https://api.github.com/repos/donnemartin/syste...       en  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Initialize the language model\n",
        "llm = OpenAI()\n",
        "\n",
        "# Create a prompt template for issue handling\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"issue_title\", \"issue_body\", \"issue_labels\", \"issue_url\", \"repository_url\", \"language\"],\n",
        "    template=(\n",
        "        \"Issue Title: {issue_title}\\n\"\n",
        "        \"Issue Body: {issue_body}\\n\"\n",
        "        \"Issue Labels: {issue_labels}\\n\"\n",
        "        \"Issue URL: {issue_url}\\n\"\n",
        "        \"Repository URL: {repository_url}\\n\"\n",
        "        \"Language: {language}\\n\"\n",
        "        \"Response:\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a chain for issue handling\n",
        "issue_handling_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "issue_title = data['title'][0]\n",
        "issue_body = data['body'][0]\n",
        "issue_labels = data['labels'][0]\n",
        "issue_url = data['issue_url'][0]\n",
        "repository_url = data['repository_url'][0]\n",
        "language = data['language'][0]\n",
        "\n",
        "response = issue_handling_chain.run({\n",
        "    \"issue_title\": issue_title,\n",
        "    \"issue_body\": issue_body,\n",
        "    \"issue_labels\": issue_labels,\n",
        "    \"issue_url\": issue_url,\n",
        "    \"repository_url\": repository_url,\n",
        "    \"language\": language\n",
        "})\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6QWT6Z8IV-b",
        "outputId": "d041d8f3-25db-48ad-9aab-931311993ce1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Title: Added python code example for parking lot\n",
            "Body: ...sign\n",
            "\n",
            "## Review the Contributing Guidelines\n",
            "\n",
            "Before submitting a pull request, verify it meets all requirements in the [Contributing Guidelines](https://github.com/donnemartin/system-design-primer/blob/master/CONTRIBUTING.md).\n",
            "\n",
            "### Translations\n",
            "\n",
            "See the [Contributing Guidelines](https://github.com/donnemartin/system-design-primer/blob/master/CONTRIBUTING.md). Verify you've:\n",
            "\n",
            "* Tagged the [language maintainer](https://github.com/donnemartin/system-design-primer/blob/master/TRANSLATIONS.md)\n",
            "* Prefixed the title with a language code\n",
            "    * Example: \"ja: Fix ...\"\n",
            "\n",
            "Issue Labels: [{\"name\": \"needs-review\", \"description\": \"none\", \"color\": \"5319e7\"}]\n",
            "Issue URL: https://api.github.com/repos/donnemartin/system-design-primer/issues/507\n",
            "Repository URL: https://api.github.com/repos/donnemartin/system-design-primer\n",
            "Language: en\n",
            "Response: Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Initialize the language model\n",
        "llm = OpenAI()\n",
        "\n",
        "# Create a prompt template for issue handling\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"issue_title\", \"issue_body\", \"issue_labels\", \"issue_url\", \"repository_url\", \"language\"],\n",
        "    template=(\n",
        "        \"Issue Title: {issue_title}\\n\"\n",
        "        \"Issue Body: {issue_body}\\n\"\n",
        "        \"Issue Labels: {issue_labels}\\n\"\n",
        "        \"Issue URL: {issue_url}\\n\"\n",
        "        \"Repository URL: {repository_url}\\n\"\n",
        "        \"Language: {language}\\n\"\n",
        "        \"Response:\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a chain for issue handling\n",
        "issue_handling_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "# Interactive loop for handling issues\n",
        "while True:\n",
        "    print(\"\\nPlease enter the details of the issue (or type 'exit' to quit):\")\n",
        "\n",
        "    # Collect user input\n",
        "    issue_title = input(\"Issue Title: \")\n",
        "    if issue_title.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    issue_body = input(\"Issue Body: \")\n",
        "    issue_labels = input(\"Issue Labels (comma-separated): \")\n",
        "    issue_url = input(\"Issue URL: \")\n",
        "    repository_url = input(\"Repository URL: \")\n",
        "    language = input(\"Language: \")\n",
        "\n",
        "    # Prepare input dictionary for the chain\n",
        "    input_data = {\n",
        "        \"issue_title\": issue_title,\n",
        "        \"issue_body\": issue_body,\n",
        "        \"issue_labels\": issue_labels,\n",
        "        \"issue_url\": issue_url,\n",
        "        \"repository_url\": repository_url,\n",
        "        \"language\": language\n",
        "    }\n",
        "\n",
        "    # Run the issue handling chain\n",
        "    response = issue_handling_chain.run(input_data)\n",
        "\n",
        "    # Print the response\n",
        "    print(\"\\nResponse:\")\n",
        "    print(response)\n"
      ],
      "metadata": {
        "id": "7_V8CRzqKyGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Initialize the language model and conversation chain\n",
        "llm = OpenAI()\n",
        "conversation_history = ChatMessageHistory()\n",
        "conversation_chain = ConversationChain(llm=llm, memory=conversation_history)\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    user_input = request.json.get('message')\n",
        "    response = conversation_chain.run(user_input)\n",
        "    return jsonify({'response': response})\n",
        "\n",
        "@app.route('/issue', methods=['POST'])\n",
        "def handle_issue():\n",
        "    issue_title = request.json.get('issue_title')\n",
        "    issue_body = request.json.get('issue_body')\n",
        "    issue_labels = request.json.get('issue_labels')\n",
        "    issue_url = request.json.get('issue_url')\n",
        "    repository_url = request.json.get('repository_url')\n",
        "    language = request.json.get('language')\n",
        "\n",
        "    response = issue_handling_chain.run({\n",
        "        \"issue_title\": issue_title,\n",
        "        \"issue_body\": issue_body,\n",
        "        \"issue_labels\": issue_labels,\n",
        "        \"issue_url\": issue_url,\n",
        "        \"repository_url\": repository_url,\n",
        "        \"language\": language\n",
        "    })\n",
        "    return jsonify({'response': response})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "fyQeOOquIwQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4oMPxogIX7T",
        "outputId": "2a348fce-b5f5-48a5-9744-1c378fb98193"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.9)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.81)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (3.0.0)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.5)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.9)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.81)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain_community) (2.7.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain_community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain_community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.5 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n"
          ]
        }
      ]
    }
  ]
}